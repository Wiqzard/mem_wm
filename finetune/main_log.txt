/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
[2025-02-03 15:36:25,102] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:36:29,985] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
WARNING: Skipping LESS=-M -I -R as it contains forbidden characters or missing values.
WARNING: Skipping MINICOM=-c on as it contains forbidden characters or missing values.
WARNING: Skipping NVIDIA_REQUIRE_CUDA=cuda>=9.0 as it contains forbidden characters or missing values.
WARNING: Skipping _CUDA_COMPAT_STATUS=CUDA Driver UNAVAILABLE (cuInit(0) returned 803) as it contains forbidden characters or missing values.
WARNING: Skipping TORCH_CUDA_ARCH_LIST=5.2 6.0 6.1 7.0 7.2 7.5 8.0 8.6 8.7 9.0+PTX as it contains forbidden characters or missing values.
WARNING: Skipping NCCL_NET=AWS Libfabric as it contains forbidden characters or missing values.
WARNING: Skipping CMD=python -u -m accelerate.commands.launch     --rdzv_conf 'rdzv_backend=c10d,rdzv_endpoint=nid005108:6000'     --config_file accelerate_config.yaml     --num_processes 8     --num_machines 2     --main_process_ip nid005108     --main_process_port 6000     --machine_rank $SLURM_PROCID     --role $(hostname -s|tr -dc '0-9'): --tee 3     train.py   --model_path THUDM/CogVideoX1.5-5B-I2V --model_name cogvideox1.5-i2v-wm --model_type wm --training_type sft --local_path /capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer   --output_dir outputs --report_to wandb   --data_root /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set --caption_column prompts.txt --image_column images_gen_new_debug.txt --video_column videos_gen_new_debug.txt --train_resolution 81x368x640   --train_epochs 100 --seed 42 --batch_size 2 --gradient_accumulation_steps 1 --mixed_precision bf16   --num_workers 8 --pin_memory False --nccl_timeout 1800   --checkpointing_steps 200 --checkpointing_limit 2   --do_validation true --validation_dir /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set --validation_steps 200 --validation_prompts prompts.txt --validation_images images_100.txt --validation_videos videos_100.txt --gen_fps 16 
 as it contains forbidden characters or missing values.
WARNING: Skipping SSH_CONNECTION=148.187.1.6 34444 172.28.11.20 22 as it contains forbidden characters or missing values.
WARNING: Skipping VSCODE_GIT_ASKPASS_EXTRA_ARGS= as it contains forbidden characters or missing values.
WARNING: Skipping LESSCLOSE=lessclose.sh %s %s as it contains forbidden characters or missing values.
WARNING: Skipping LESSOPEN=lessopen.sh %s as it contains forbidden characters or missing values.
WARNING: Skipping NVM_CD_FLAGS= as it contains forbidden characters or missing values.
WARNING: Skipping SSH_CLIENT=148.187.1.6 34444 22 as it contains forbidden characters or missing values.
WARNING: Skipping NVIDIA_REQUIRE_JETPACK_HOST_MOUNTS= as it contains forbidden characters or missing values.
WARNING: Skipping BASH_FUNC_ml%%=() {  eval "$($LMOD_DIR/ml_cmd "$@")"
} as it contains forbidden characters or missing values.
WARNING: Skipping BASH_FUNC_module%%=() {  if [ -z "${LMOD_SH_DBG_ON+x}" ]; then
 case "$-" in 
 *v*x*)
 __lmod_sh_dbg='vx'
 ;;
 *v*)
 __lmod_sh_dbg='v'
 ;;
 *x*)
 __lmod_sh_dbg='x'
 ;;
 esac;
 fi;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 set +$__lmod_sh_dbg;
 echo "Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output" 1>&2;
 fi;
 eval "$($LMOD_CMD shell "$@")" && eval "$(${LMOD_SETTARG_CMD:-:} -s sh)";
 __lmod_my_status=$?;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 echo "Shell debugging restarted" 1>&2;
 set -$__lmod_sh_dbg;
 fi;
 unset __lmod_sh_dbg;
 return $__lmod_my_status
} as it contains forbidden characters or missing values.
WARNING: Skipping LESS=-M -I -R as it contains forbidden characters or missing values.
WARNING: Skipping MINICOM=-c on as it contains forbidden characters or missing values.
WARNING: Skipping NVIDIA_REQUIRE_CUDA=cuda>=9.0 as it contains forbidden characters or missing values.
WARNING: Skipping _CUDA_COMPAT_STATUS=CUDA Driver UNAVAILABLE (cuInit(0) returned 803) as it contains forbidden characters or missing values.
WARNING: Skipping TORCH_CUDA_ARCH_LIST=5.2 6.0 6.1 7.0 7.2 7.5 8.0 8.6 8.7 9.0+PTX as it contains forbidden characters or missing values.
WARNING: Skipping NCCL_NET=AWS Libfabric as it contains forbidden characters or missing values.
WARNING: Skipping CMD=python -u -m accelerate.commands.launch     --rdzv_conf 'rdzv_backend=c10d,rdzv_endpoint=nid005108:6000'     --config_file accelerate_config.yaml     --num_processes 8     --num_machines 2     --main_process_ip nid005108     --main_process_port 6000     --machine_rank $SLURM_PROCID     --role $(hostname -s|tr -dc '0-9'): --tee 3     train.py   --model_path THUDM/CogVideoX1.5-5B-I2V --model_name cogvideox1.5-i2v-wm --model_type wm --training_type sft --local_path /capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer   --output_dir outputs --report_to wandb   --data_root /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set --caption_column prompts.txt --image_column images_gen_new_debug.txt --video_column videos_gen_new_debug.txt --train_resolution 81x368x640   --train_epochs 100 --seed 42 --batch_size 2 --gradient_accumulation_steps 1 --mixed_precision bf16   --num_workers 8 --pin_memory False --nccl_timeout 1800   --checkpointing_steps 200 --checkpointing_limit 2   --do_validation true --validation_dir /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set --validation_steps 200 --validation_prompts prompts.txt --validation_images images_100.txt --validation_videos videos_100.txt --gen_fps 16 
 as it contains forbidden characters or missing values.
WARNING: Skipping SSH_CONNECTION=148.187.1.6 34444 172.28.11.20 22 as it contains forbidden characters or missing values.
WARNING: Skipping VSCODE_GIT_ASKPASS_EXTRA_ARGS= as it contains forbidden characters or missing values.
WARNING: Skipping LESSCLOSE=lessclose.sh %s %s as it contains forbidden characters or missing values.
WARNING: Skipping LESSOPEN=lessopen.sh %s as it contains forbidden characters or missing values.
WARNING: Skipping NVM_CD_FLAGS= as it contains forbidden characters or missing values.
WARNING: Skipping SSH_CLIENT=148.187.1.6 34444 22 as it contains forbidden characters or missing values.
WARNING: Skipping NVIDIA_REQUIRE_JETPACK_HOST_MOUNTS= as it contains forbidden characters or missing values.
WARNING: Skipping BASH_FUNC_ml%%=() {  eval "$($LMOD_DIR/ml_cmd "$@")"
} as it contains forbidden characters or missing values.
WARNING: Skipping BASH_FUNC_module%%=() {  if [ -z "${LMOD_SH_DBG_ON+x}" ]; then
 case "$-" in 
 *v*x*)
 __lmod_sh_dbg='vx'
 ;;
 *v*)
 __lmod_sh_dbg='v'
 ;;
 *x*)
 __lmod_sh_dbg='x'
 ;;
 esac;
 fi;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 set +$__lmod_sh_dbg;
 echo "Shell debugging temporarily silenced: export LMOD_SH_DBG_ON=1 for Lmod's output" 1>&2;
 fi;
 eval "$($LMOD_CMD shell "$@")" && eval "$(${LMOD_SETTARG_CMD:-:} -s sh)";
 __lmod_my_status=$?;
 if [ -n "${__lmod_sh_dbg:-}" ]; then
 echo "Shell debugging restarted" 1>&2;
 set -$__lmod_sh_dbg;
 fi;
 unset __lmod_sh_dbg;
 return $__lmod_my_status
} as it contains forbidden characters or missing values.
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
[2025-02-03 15:36:41,301] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:36:41,647] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:36:44,093] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2025-02-03 15:36:44,093] [INFO] [runner.py:607:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=6000 --no_local_rank --enable_each_rank_log=None train.py --model_path THUDM/CogVideoX1.5-5B-I2V --model_name cogvideox1.5-i2v-wm --model_type wm --training_type sft --local_path /capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer --output_dir outputs --report_to wandb --data_root /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set --caption_column prompts.txt --image_column images_gen_new_debug.txt --video_column videos_gen_new_debug.txt --train_resolution 81x368x640 --train_epochs 100 --seed 42 --batch_size 2 --gradient_accumulation_steps 1 --mixed_precision bf16 --num_workers 8 --pin_memory False --nccl_timeout 1800 --checkpointing_steps 200 --checkpointing_limit 2 --do_validation true --validation_dir /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set --validation_steps 200 --validation_prompts prompts.txt --validation_images images_100.txt --validation_videos videos_100.txt --gen_fps 16
[2025-02-03 15:36:44,157] [WARNING] [runner.py:215:fetch_hostfile] Unable to find hostfile, will proceed with training with local resources only.
Detected VISIBLE_DEVICES=0,1,2,3 but ignoring it because one or several of --include/--exclude/--num_gpus/--num_nodes cl args were used. If you want to use CUDA_VISIBLE_DEVICES don't pass any of these arguments to deepspeed.
[2025-02-03 15:36:44,157] [INFO] [runner.py:607:main] cmd = /usr/bin/python -u -m deepspeed.launcher.launch --world_info=eyJsb2NhbGhvc3QiOiBbMCwgMSwgMiwgM119 --master_addr=127.0.0.1 --master_port=6000 --no_local_rank --enable_each_rank_log=None train.py --model_path THUDM/CogVideoX1.5-5B-I2V --model_name cogvideox1.5-i2v-wm --model_type wm --training_type sft --local_path /capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer --output_dir outputs --report_to wandb --data_root /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set --caption_column prompts.txt --image_column images_gen_new_debug.txt --video_column videos_gen_new_debug.txt --train_resolution 81x368x640 --train_epochs 100 --seed 42 --batch_size 2 --gradient_accumulation_steps 1 --mixed_precision bf16 --num_workers 8 --pin_memory False --nccl_timeout 1800 --checkpointing_steps 200 --checkpointing_limit 2 --do_validation true --validation_dir /capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set --validation_steps 200 --validation_prompts prompts.txt --validation_images images_100.txt --validation_videos videos_100.txt --gen_fps 16
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
[2025-02-03 15:36:46,131] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:36:46,319] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:36:48,567] [INFO] [launch.py:139:main] 0 NCCL_NET_PLUGIN=ofi
[2025-02-03 15:36:48,567] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.19.4
[2025-02-03 15:36:48,567] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3
[2025-02-03 15:36:48,567] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PHB
[2025-02-03 15:36:48,568] [INFO] [launch.py:139:main] 0 NCCL_NET=AWS Libfabric
[2025-02-03 15:36:48,568] [INFO] [launch.py:139:main] 0 NCCL_CROSS_NIC=1
[2025-02-03 15:36:48,568] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-02-03 15:36:48,568] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-02-03 15:36:48,568] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-02-03 15:36:48,568] [INFO] [launch.py:164:main] dist_world_size=4
[2025-02-03 15:36:48,568] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-02-03 15:36:48,569] [INFO] [launch.py:256:main] process 81827 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:48,569] [INFO] [launch.py:256:main] process 81828 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:48,570] [INFO] [launch.py:256:main] process 81829 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:48,570] [INFO] [launch.py:256:main] process 81830 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:49,159] [INFO] [launch.py:139:main] 0 NCCL_NET_PLUGIN=ofi
[2025-02-03 15:36:49,159] [INFO] [launch.py:139:main] 0 NCCL_VERSION=2.19.4
[2025-02-03 15:36:49,159] [INFO] [launch.py:139:main] 0 NCCL_SOCKET_IFNAME=hsn0,hsn1,hsn2,hsn3
[2025-02-03 15:36:49,159] [INFO] [launch.py:139:main] 0 NCCL_NET_GDR_LEVEL=PHB
[2025-02-03 15:36:49,160] [INFO] [launch.py:139:main] 0 NCCL_NET=AWS Libfabric
[2025-02-03 15:36:49,160] [INFO] [launch.py:139:main] 0 NCCL_CROSS_NIC=1
[2025-02-03 15:36:49,160] [INFO] [launch.py:146:main] WORLD INFO DICT: {'localhost': [0, 1, 2, 3]}
[2025-02-03 15:36:49,160] [INFO] [launch.py:152:main] nnodes=1, num_local_procs=4, node_rank=0
[2025-02-03 15:36:49,160] [INFO] [launch.py:163:main] global_rank_mapping=defaultdict(<class 'list'>, {'localhost': [0, 1, 2, 3]})
[2025-02-03 15:36:49,160] [INFO] [launch.py:164:main] dist_world_size=4
[2025-02-03 15:36:49,160] [INFO] [launch.py:168:main] Setting CUDA_VISIBLE_DEVICES=0,1,2,3
[2025-02-03 15:36:49,161] [INFO] [launch.py:256:main] process 263449 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:49,162] [INFO] [launch.py:256:main] process 263450 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:49,163] [INFO] [launch.py:256:main] process 263451 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
[2025-02-03 15:36:49,164] [INFO] [launch.py:256:main] process 263452 spawned with command: ['/usr/bin/python', '-u', 'train.py', '--model_path', 'THUDM/CogVideoX1.5-5B-I2V', '--model_name', 'cogvideox1.5-i2v-wm', '--model_type', 'wm', '--training_type', 'sft', '--local_path', '/capstor/scratch/cscs/sstapf/mem_wm/outputs/transformer', '--output_dir', 'outputs', '--report_to', 'wandb', '--data_root', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/train_set', '--caption_column', 'prompts.txt', '--image_column', 'images_gen_new_debug.txt', '--video_column', 'videos_gen_new_debug.txt', '--train_resolution', '81x368x640', '--train_epochs', '100', '--seed', '42', '--batch_size', '2', '--gradient_accumulation_steps', '1', '--mixed_precision', 'bf16', '--num_workers', '8', '--pin_memory', 'False', '--nccl_timeout', '1800', '--checkpointing_steps', '200', '--checkpointing_limit', '2', '--do_validation', 'true', '--validation_dir', '/capstor/store/cscs/swissai/a03/datasets/ego4d_mc/validation_set', '--validation_steps', '200', '--validation_prompts', 'prompts.txt', '--validation_images', 'images_100.txt', '--validation_videos', 'videos_100.txt', '--gen_fps', '16']
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
[2025-02-03 15:37:09,274] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,277] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,277] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,278] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,280] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,280] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,280] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:09,282] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-02-03 15:37:10,325] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,325] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-02-03 15:37:10,388] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,435] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,435] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,487] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,488] [INFO] [comm.py:683:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-02-03 15:37:10,493] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,525] [INFO] [comm.py:652:init_distributed] cdb=None
[2025-02-03 15:37:10,525] [INFO] [comm.py:652:init_distributed] cdb=None
02/03/2025 15:37:10 - INFO - trainer - Initialized Trainer
02/03/2025 15:37:10 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

02/03/2025 15:37:10 - INFO - trainer - Initializing models
02/03/2025 15:37:10 - INFO - trainer - Initializing dataset and dataloader
dataset initializing
dataset initialized
02/03/2025 15:37:10 - INFO - trainer - Initialized Trainer
02/03/2025 15:37:10 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

02/03/2025 15:37:10 - INFO - trainer - Initializing models
02/03/2025 15:37:10 - INFO - trainer - Initializing dataset and dataloader
dataset initializing
dataset initialized
02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

dataset initializing
dataset initialized
02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

dataset initializing
dataset initialized
02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 3
Local process index: 3
Device: cuda:3

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

dataset initializing
dataset initialized
02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

dataset initializing
dataset initialized
02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 1
Local process index: 1
Device: cuda:1

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

02/03/2025 15:37:11 - INFO - trainer - Accelerator state: 
Distributed environment: DEEPSPEED  Backend: nccl
Num processes: 4
Process index: 2
Local process index: 2
Device: cuda:2

Mixed precision type: bf16
ds_config: {'bf16': {'enabled': True}, 'optimizer': {'type': 'AdamW', 'params': {'lr': 'auto', 'weight_decay': 'auto', 'torch_adam': True, 'adam_w_mode': True}}, 'scheduler': {'type': 'WarmupDecayLR', 'params': {'warmup_min_lr': 'auto', 'warmup_max_lr': 'auto', 'warmup_num_steps': 'auto', 'total_num_steps': 'auto'}}, 'zero_optimization': {'stage': 2, 'allgather_partitions': True, 'allgather_bucket_size': 200000000.0, 'overlap_comm': True, 'reduce_scatter': True, 'reduce_bucket_size': 500000000.0, 'contiguous_gradients': True}, 'gradient_accumulation_steps': 1, 'train_micro_batch_size_per_gpu': 1, 'train_batch_size': 'auto', 'gradient_clipping': 'auto', 'steps_per_print': inf, 'wall_clock_breakdown': False, 'fp16': {'enabled': False}}

dataset initializing
dataset initializing
dataset initializeddataset initialized

[2025-02-03 15:37:15,785] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:37:15,867] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:37:15,978] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:37:16,188] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
02/03/2025 15:37:16 - INFO - trainer - Initializing trainable parameters
02/03/2025 15:37:16 - INFO - trainer - Initializing optimizer and lr scheduler
[2025-02-03 15:37:16,247] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.3, git-hash=unknown, git-branch=unknown
[2025-02-03 15:37:16,247] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:37:16,278] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
02/03/2025 15:37:16 - INFO - trainer - Initializing trainable parameters
02/03/2025 15:37:16 - INFO - trainer - Initializing optimizer and lr scheduler
[2025-02-03 15:37:16,410] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed info: version=0.16.3, git-hash=unknown, git-branch=unknown
[2025-02-03 15:37:16,410] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:37:16,483] [INFO] [config.py:733:__init__] Config mesh_device None world_size = 4
[2025-02-03 15:39:16,841] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-02-03 15:39:16,843] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-02-03 15:39:16,843] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-02-03 15:39:16,928] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-02-03 15:39:16,928] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-02-03 15:39:16,928] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-02-03 15:39:16,928] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-02-03 15:39:16,928] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2025-02-03 15:39:16,928] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-02-03 15:39:16,928] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-02-03 15:39:16,954] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2025-02-03 15:39:16,955] [INFO] [logging.py:128:log_dist] [Rank 0] Using DeepSpeed Optimizer param name adamw as basic optimizer
[2025-02-03 15:39:16,955] [INFO] [logging.py:128:log_dist] [Rank 0] Removing param_group that has no 'params' in the basic Optimizer
[2025-02-03 15:39:17,038] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Basic Optimizer = AdamW
[2025-02-03 15:39:17,038] [INFO] [utils.py:59:is_zero_supported_optimizer] Checking ZeRO support for optimizer=AdamW type=<class 'torch.optim.adamw.AdamW'>
[2025-02-03 15:39:17,039] [INFO] [logging.py:128:log_dist] [Rank 0] Creating torch.bfloat16 ZeRO stage 2 optimizer
[2025-02-03 15:39:17,039] [INFO] [stage_1_and_2.py:149:__init__] Reduce bucket size 500000000
[2025-02-03 15:39:17,039] [INFO] [stage_1_and_2.py:150:__init__] Allgather bucket size 200000000
[2025-02-03 15:39:17,039] [INFO] [stage_1_and_2.py:151:__init__] CPU Offload: False
[2025-02-03 15:39:17,039] [INFO] [stage_1_and_2.py:152:__init__] Round robin gradient partitioning: False
[2025-02-03 15:39:49,960] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:51,393] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:51,858] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:52,121] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:52,248] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:52,250] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-02-03 15:39:52,252] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 18.58 GB         CA 18.61 GB         Max_CA 19 GB 
[2025-02-03 15:39:52,253] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 413.47 GB, percent = 48.4%
[2025-02-03 15:39:52,575] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:52,592] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-02-03 15:39:52,593] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 21.17 GB         CA 23.8 GB         Max_CA 24 GB 
[2025-02-03 15:39:52,593] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 283.29 GB, percent = 33.2%
[2025-02-03 15:39:52,593] [INFO] [stage_1_and_2.py:545:__init__] optimizer state initialized
[2025-02-03 15:39:52,832] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-02-03 15:39:52,833] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 15.98 GB         CA 23.8 GB         Max_CA 24 GB 
[2025-02-03 15:39:52,833] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 275.49 GB, percent = 32.2%
[2025-02-03 15:39:52,842] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-02-03 15:39:52,842] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:52,842] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2025-02-03 15:39:52,842] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x4004f111efb0>
[2025-02-03 15:39:52,842] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0, 0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-02-03 15:39:52,845] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-02-03 15:39:52,845] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-02-03 15:39:52,845] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-02-03 15:39:52,845] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-02-03 15:39:52,845] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-02-03 15:39:52,845] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x4004d4f69a20>
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-02-03 15:39:52,846] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-02-03 15:39:52,847] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-02-03 15:39:52,848] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   optimizer_name ............... adamw
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   optimizer_params ............. {'lr': 2e-05, 'weight_decay': 0.0001}
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   scheduler_name ............... WarmupDecayLR
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 2e-05, 'warmup_num_steps': 0, 'total_num_steps': 500}
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-02-03 15:39:52,849] [INFO] [config.py:1003:print]   train_batch_size ............. 4
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   world_size ................... 4
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-02-03 15:39:52,850] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2025-02-03 15:39:52,850] [INFO] [config.py:989:print_user_config]   json = {
    "bf16": {
        "enabled": true
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 2e-05, 
            "weight_decay": 0.0001
        }
    }, 
    "scheduler": {
        "type": "WarmupDecayLR", 
        "params": {
            "warmup_min_lr": 0, 
            "warmup_max_lr": 2e-05, 
            "warmup_num_steps": 0, 
            "total_num_steps": 500
        }
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "train_batch_size": 4, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }
}
02/03/2025 15:39:52 - INFO - trainer - Initializing trackers
wandb: Currently logged in as: wiqzard to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[2025-02-03 15:39:53,412] [INFO] [utils.py:781:see_memory_usage] Before initializing optimizer states
[2025-02-03 15:39:53,413] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 18.58 GB         CA 18.61 GB         Max_CA 19 GB 
[2025-02-03 15:39:53,414] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 221.02 GB, percent = 25.9%
[2025-02-03 15:39:53,671] [INFO] [utils.py:781:see_memory_usage] After initializing optimizer states
[2025-02-03 15:39:53,672] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 21.17 GB         CA 23.8 GB         Max_CA 24 GB 
[2025-02-03 15:39:53,672] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 225.72 GB, percent = 26.4%
[2025-02-03 15:39:53,672] [INFO] [stage_1_and_2.py:545:__init__] optimizer state initialized
[2025-02-03 15:39:53,899] [INFO] [utils.py:781:see_memory_usage] After initializing ZeRO optimizer
[2025-02-03 15:39:53,900] [INFO] [utils.py:782:see_memory_usage] MA 15.98 GB         Max_MA 15.98 GB         CA 23.8 GB         Max_CA 24 GB 
[2025-02-03 15:39:53,900] [INFO] [utils.py:789:see_memory_usage] CPU Virtual Memory:  used = 225.74 GB, percent = 26.4%
[2025-02-03 15:39:53,907] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedZeroOptimizer
[2025-02-03 15:39:53,908] [WARNING] [lr_schedules.py:683:get_lr] Attempting to get learning rate from scheduler before it has started
[2025-02-03 15:39:53,908] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed using configured LR scheduler = WarmupDecayLR
[2025-02-03 15:39:53,908] [INFO] [logging.py:128:log_dist] [Rank 0] DeepSpeed LR Scheduler = <deepspeed.runtime.lr_schedules.WarmupDecayLR object at 0x400522e52fe0>
[2025-02-03 15:39:53,908] [INFO] [logging.py:128:log_dist] [Rank 0] step=0, skipped=0, lr=[0, 0], mom=[(0.9, 0.999), (0.9, 0.999)]
[2025-02-03 15:39:53,910] [INFO] [config.py:999:print] DeepSpeedEngine configuration:
[2025-02-03 15:39:53,910] [INFO] [config.py:1003:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True, 'use_gds': False}
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   amp_enabled .................. False
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   amp_params ................... False
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   bfloat16_enabled ............. True
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   bfloat16_immediate_grad_update  False
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   checkpoint_parallel_write_pipeline  False
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   checkpoint_tag_validation_enabled  True
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   checkpoint_tag_validation_fail  False
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x400506c599f0>
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   communication_data_type ...... None
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2025-02-03 15:39:53,911] [INFO] [config.py:1003:print]   curriculum_enabled_legacy .... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   curriculum_params_legacy ..... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   data_efficiency_enabled ...... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   dataloader_drop_last ......... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   disable_allgather ............ False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   dump_state ................... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   dynamic_loss_scale_args ...... None
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   eigenvalue_enabled ........... False
[2025-02-03 15:39:53,912] [INFO] [config.py:1003:print]   eigenvalue_gas_boundary_resolution  1
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_layer_num ......... 0
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_max_iter .......... 100
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_stability ......... 1e-06
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_tol ............... 0.01
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   eigenvalue_verbose ........... False
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   elasticity_enabled ........... False
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   fp16_auto_cast ............... None
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   fp16_enabled ................. False
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   fp16_master_weights_and_gradients  False
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   global_rank .................. 0
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   grad_accum_dtype ............. None
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   gradient_accumulation_steps .. 1
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   gradient_clipping ............ 1.0
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   gradient_predivide_factor .... 1.0
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   graph_harvesting ............. False
[2025-02-03 15:39:53,913] [INFO] [config.py:1003:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   initial_dynamic_scale ........ 1
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   load_universal_checkpoint .... False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   loss_scale ................... 1.0
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   memory_breakdown ............. False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   mics_hierarchial_params_gather  False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   mics_shard_size .............. -1
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') comet=CometConfig(enabled=False, samples_log_interval=100, project=None, workspace=None, api_key=None, experiment_name=None, experiment_key=None, online=None, mode=None) wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName')
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   optimizer_legacy_fusion ...... False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   optimizer_name ............... adamw
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   optimizer_params ............. {'lr': 2e-05, 'weight_decay': 0.0001}
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   pld_enabled .................. False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   pld_params ................... False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   prescale_gradients ........... False
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   scheduler_name ............... WarmupDecayLR
[2025-02-03 15:39:53,914] [INFO] [config.py:1003:print]   scheduler_params ............. {'warmup_min_lr': 0, 'warmup_max_lr': 2e-05, 'warmup_num_steps': 0, 'total_num_steps': 500}
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   seq_parallel_communication_data_type  torch.float32
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   sparse_attention ............. None
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   sparse_gradients_enabled ..... False
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   steps_per_print .............. inf
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   timers_config ................ enabled=True synchronized=True
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   train_batch_size ............. 4
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   train_micro_batch_size_per_gpu  1
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   use_data_before_expert_parallel_  False
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   use_node_local_storage ....... False
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   wall_clock_breakdown ......... False
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   weight_quantization_config ... None
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   world_size ................... 4
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   zero_allow_untested_optimizer  False
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500000000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=200000000 overlap_comm=True load_from_fp32_weights=True elastic_checkpoint=False offload_param=None offload_optimizer=None sub_group_size=1000000000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50000000 param_persistence_threshold=100000 model_persistence_threshold=9223372036854775807 max_live_parameters=1000000000 max_reuse_distance=1000000000 gather_16bit_weights_on_model_save=False module_granularity_threshold=0 use_all_reduce_for_fetch_params=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False zeropp_loco_param=None mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   zero_enabled ................. True
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   zero_force_ds_cpu_optimizer .. True
[2025-02-03 15:39:53,915] [INFO] [config.py:1003:print]   zero_optimization_stage ...... 2
[2025-02-03 15:39:53,915] [INFO] [config.py:989:print_user_config]   json = {
    "bf16": {
        "enabled": true
    }, 
    "optimizer": {
        "type": "AdamW", 
        "params": {
            "lr": 2e-05, 
            "weight_decay": 0.0001
        }
    }, 
    "scheduler": {
        "type": "WarmupDecayLR", 
        "params": {
            "warmup_min_lr": 0, 
            "warmup_max_lr": 2e-05, 
            "warmup_num_steps": 0, 
            "total_num_steps": 500
        }
    }, 
    "zero_optimization": {
        "stage": 2, 
        "allgather_partitions": true, 
        "allgather_bucket_size": 2.000000e+08, 
        "overlap_comm": true, 
        "reduce_scatter": true, 
        "reduce_bucket_size": 5.000000e+08, 
        "contiguous_gradients": true
    }, 
    "gradient_accumulation_steps": 1, 
    "train_micro_batch_size_per_gpu": 1, 
    "train_batch_size": 4, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "wall_clock_breakdown": false, 
    "fp16": {
        "enabled": false
    }
}
02/03/2025 15:39:53 - INFO - trainer - Initializing trackers
wandb: Tracking run with wandb version 0.19.5
wandb: Run data is saved locally in /capstor/scratch/cscs/sstapf/mem_wm/finetune/wandb/run-20250203_153953-7x0547k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-cosmos-81
wandb: ⭐️ View project at https://wandb.ai/wiqzard/gem_inf
wandb: 🚀 View run at https://wandb.ai/wiqzard/gem_inf/runs/7x0547k8
wandb: Currently logged in as: wiqzard to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
02/03/2025 15:39:54 - INFO - trainer - Starting training
02/03/2025 15:39:54 - INFO - trainer - Memory before training start: {
    "memory_allocated": 15.983,
    "memory_reserved": 23.799,
    "max_memory_allocated": 15.983,
    "max_memory_reserved": 23.799
}
02/03/2025 15:39:54 - INFO - trainer - Training configuration: {
    "trainable parameters": 5572216448,
    "total samples": 10,
    "train epochs": 100,
    "train steps": 200,
    "batches per device": 2,
    "total batches observed per epoch": 2,
    "train batch size total count": 8,
    "gradient accumulation steps": 1
}
wandb: Tracking run with wandb version 0.19.5
wandb: Run data is saved locally in /capstor/scratch/cscs/sstapf/mem_wm/finetune/wandb/run-20250203_153954-czxq6sbe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-yogurt-82
wandb: ⭐️ View project at https://wandb.ai/wiqzard/gem_inf
wandb: 🚀 View run at https://wandb.ai/wiqzard/gem_inf/runs/czxq6sbe
02/03/2025 15:39:55 - INFO - trainer - Starting training
02/03/2025 15:39:55 - INFO - trainer - Memory before training start: {
    "memory_allocated": 15.983,
    "memory_reserved": 23.799,
    "max_memory_allocated": 15.983,
    "max_memory_reserved": 23.799
}
02/03/2025 15:39:55 - INFO - trainer - Training configuration: {
    "trainable parameters": 5572216448,
    "total samples": 10,
    "train epochs": 100,
    "train steps": 200,
    "batches per device": 2,
    "total batches observed per epoch": 2,
    "train batch size total count": 8,
    "gradient accumulation steps": 1
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   0%|          | 0/200 [00:00<?, ?it/s]Training steps:   0%|          | 1/200 [00:19<1:03:14, 19.07s/it]Training steps:   0%|          | 1/200 [00:19<1:03:14, 19.07s/it, grad_norm=3.98, loss=1.21, lr=0]Training steps:   1%|          | 2/200 [00:24<36:11, 10.97s/it, grad_norm=3.98, loss=1.21, lr=0]  Training steps:   1%|          | 2/200 [00:24<36:11, 10.97s/it, grad_norm=1.73, loss=1.03, lr=2e-5]02/03/2025 15:40:19 - INFO - trainer - Memory after epoch 1: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.817,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   0%|          | 0/200 [00:00<?, ?it/s]Training steps:   0%|          | 1/200 [00:20<1:06:35, 20.08s/it]Training steps:   0%|          | 1/200 [00:20<1:06:35, 20.08s/it, grad_norm=3.98, loss=1.21, lr=0]Training steps:   1%|          | 2/200 [00:25<37:30, 11.37s/it, grad_norm=3.98, loss=1.21, lr=0]  Training steps:   1%|          | 2/200 [00:25<37:30, 11.37s/it, grad_norm=1.73, loss=1.03, lr=2e-5]02/03/2025 15:40:20 - INFO - trainer - Memory after epoch 1: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.817,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   2%|▏         | 3/200 [00:30<28:05,  8.56s/it, grad_norm=1.73, loss=1.03, lr=2e-5]Training steps:   2%|▏         | 3/200 [00:30<28:05,  8.56s/it, grad_norm=2.51, loss=1.05, lr=2e-5]Training steps:   2%|▏         | 4/200 [00:35<23:44,  7.27s/it, grad_norm=2.51, loss=1.05, lr=2e-5]Training steps:   2%|▏         | 4/200 [00:35<23:44,  7.27s/it, grad_norm=3.61, loss=1.12, lr=2e-5]02/03/2025 15:40:30 - INFO - trainer - Memory after epoch 2: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   2%|▏         | 3/200 [00:31<28:47,  8.77s/it, grad_norm=1.73, loss=1.03, lr=2e-5]Training steps:   2%|▏         | 3/200 [00:31<28:47,  8.77s/it, grad_norm=2.51, loss=1.05, lr=2e-5]Training steps:   2%|▏         | 4/200 [00:36<24:07,  7.39s/it, grad_norm=2.51, loss=1.05, lr=2e-5]Training steps:   2%|▏         | 4/200 [00:36<24:07,  7.39s/it, grad_norm=3.61, loss=1.12, lr=2e-5]02/03/2025 15:40:31 - INFO - trainer - Memory after epoch 2: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   2%|▎         | 5/200 [00:41<21:47,  6.70s/it, grad_norm=3.61, loss=1.12, lr=2e-5]Training steps:   2%|▎         | 5/200 [00:41<21:47,  6.70s/it, grad_norm=5.29, loss=1.06, lr=1.99e-5]Training steps:   3%|▎         | 6/200 [00:46<20:07,  6.22s/it, grad_norm=5.29, loss=1.06, lr=1.99e-5]Training steps:   3%|▎         | 6/200 [00:46<20:07,  6.22s/it, grad_norm=1.85, loss=0.599, lr=1.99e-5]02/03/2025 15:40:41 - INFO - trainer - Memory after epoch 3: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   2%|▎         | 5/200 [00:41<21:57,  6.75s/it, grad_norm=3.61, loss=1.12, lr=2e-5]Training steps:   2%|▎         | 5/200 [00:41<21:57,  6.75s/it, grad_norm=5.29, loss=1.06, lr=1.99e-5]Training steps:   3%|▎         | 6/200 [00:47<20:13,  6.25s/it, grad_norm=5.29, loss=1.06, lr=1.99e-5]Training steps:   3%|▎         | 6/200 [00:47<20:13,  6.25s/it, grad_norm=1.85, loss=0.599, lr=1.99e-5]02/03/2025 15:40:42 - INFO - trainer - Memory after epoch 3: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   4%|▎         | 7/200 [00:51<19:25,  6.04s/it, grad_norm=1.85, loss=0.599, lr=1.99e-5]Training steps:   4%|▎         | 7/200 [00:51<19:25,  6.04s/it, grad_norm=4.82, loss=1.04, lr=1.98e-5] Training steps:   4%|▍         | 8/200 [00:57<18:33,  5.80s/it, grad_norm=4.82, loss=1.04, lr=1.98e-5]Training steps:   4%|▍         | 8/200 [00:57<18:33,  5.80s/it, grad_norm=0.695, loss=0.372, lr=1.98e-5]02/03/2025 15:40:52 - INFO - trainer - Memory after epoch 4: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   4%|▎         | 7/200 [00:52<19:25,  6.04s/it, grad_norm=1.85, loss=0.599, lr=1.99e-5]Training steps:   4%|▎         | 7/200 [00:52<19:25,  6.04s/it, grad_norm=4.82, loss=1.04, lr=1.98e-5] Training steps:   4%|▍         | 8/200 [00:58<18:33,  5.80s/it, grad_norm=4.82, loss=1.04, lr=1.98e-5]Training steps:   4%|▍         | 8/200 [00:58<18:33,  5.80s/it, grad_norm=0.695, loss=0.372, lr=1.98e-5]02/03/2025 15:40:53 - INFO - trainer - Memory after epoch 4: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   4%|▍         | 9/200 [01:02<18:18,  5.75s/it, grad_norm=0.695, loss=0.372, lr=1.98e-5]Training steps:   4%|▍         | 9/200 [01:02<18:18,  5.75s/it, grad_norm=1.16, loss=0.415, lr=1.98e-5] Training steps:   5%|▌         | 10/200 [01:08<17:46,  5.61s/it, grad_norm=1.16, loss=0.415, lr=1.98e-5]Training steps:   5%|▌         | 10/200 [01:08<17:46,  5.61s/it, grad_norm=2.6, loss=0.766, lr=1.97e-5] 02/03/2025 15:41:03 - INFO - trainer - Memory after epoch 5: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   4%|▍         | 9/200 [01:03<18:19,  5.76s/it, grad_norm=0.695, loss=0.372, lr=1.98e-5]Training steps:   4%|▍         | 9/200 [01:03<18:19,  5.76s/it, grad_norm=1.16, loss=0.415, lr=1.98e-5] Training steps:   5%|▌         | 10/200 [01:09<17:45,  5.61s/it, grad_norm=1.16, loss=0.415, lr=1.98e-5]Training steps:   5%|▌         | 10/200 [01:09<17:45,  5.61s/it, grad_norm=2.6, loss=0.766, lr=1.97e-5] 02/03/2025 15:41:04 - INFO - trainer - Memory after epoch 5: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   6%|▌         | 11/200 [01:13<17:42,  5.62s/it, grad_norm=2.6, loss=0.766, lr=1.97e-5]Training steps:   6%|▌         | 11/200 [01:13<17:42,  5.62s/it, grad_norm=1.35, loss=0.436, lr=1.97e-5]Training steps:   6%|▌         | 12/200 [01:19<17:19,  5.53s/it, grad_norm=1.35, loss=0.436, lr=1.97e-5]Training steps:   6%|▌         | 12/200 [01:19<17:19,  5.53s/it, grad_norm=1.19, loss=0.362, lr=1.96e-5]02/03/2025 15:41:13 - INFO - trainer - Memory after epoch 6: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   6%|▌         | 11/200 [01:14<17:47,  5.65s/it, grad_norm=2.6, loss=0.766, lr=1.97e-5]Training steps:   6%|▌         | 11/200 [01:14<17:47,  5.65s/it, grad_norm=1.35, loss=0.436, lr=1.97e-5]Training steps:   6%|▌         | 12/200 [01:20<17:21,  5.54s/it, grad_norm=1.35, loss=0.436, lr=1.97e-5]Training steps:   6%|▌         | 12/200 [01:20<17:21,  5.54s/it, grad_norm=1.19, loss=0.362, lr=1.96e-5]02/03/2025 15:41:15 - INFO - trainer - Memory after epoch 6: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
Training steps:   6%|▋         | 13/200 [01:24<17:18,  5.56s/it, grad_norm=1.19, loss=0.362, lr=1.96e-5]Training steps:   6%|▋         | 13/200 [01:24<17:18,  5.56s/it, grad_norm=1.93, loss=0.646, lr=1.96e-5]Training steps:   7%|▋         | 14/200 [01:30<16:59,  5.48s/it, grad_norm=1.93, loss=0.646, lr=1.96e-5]Training steps:   7%|▋         | 14/200 [01:30<16:59,  5.48s/it, grad_norm=2.67, loss=0.639, lr=1.96e-5]02/03/2025 15:41:24 - INFO - trainer - Memory after epoch 7: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   6%|▋         | 13/200 [01:25<17:23,  5.58s/it, grad_norm=1.19, loss=0.362, lr=1.96e-5]Training steps:   6%|▋         | 13/200 [01:25<17:23,  5.58s/it, grad_norm=1.93, loss=0.646, lr=1.96e-5]Training steps:   7%|▋         | 14/200 [01:31<17:01,  5.49s/it, grad_norm=1.93, loss=0.646, lr=1.96e-5]Training steps:   7%|▋         | 14/200 [01:31<17:01,  5.49s/it, grad_norm=2.67, loss=0.639, lr=1.96e-5]02/03/2025 15:41:26 - INFO - trainer - Memory after epoch 7: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   8%|▊         | 15/200 [01:35<17:01,  5.52s/it, grad_norm=2.67, loss=0.639, lr=1.96e-5]Training steps:   8%|▊         | 15/200 [01:35<17:01,  5.52s/it, grad_norm=1.24, loss=0.437, lr=1.95e-5]Training steps:   8%|▊         | 16/200 [01:41<16:45,  5.46s/it, grad_norm=1.24, loss=0.437, lr=1.95e-5]Training steps:   8%|▊         | 16/200 [01:41<16:45,  5.46s/it, grad_norm=1.7, loss=0.649, lr=1.95e-5] 02/03/2025 15:41:35 - INFO - trainer - Memory after epoch 8: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   8%|▊         | 15/200 [01:36<17:06,  5.55s/it, grad_norm=2.67, loss=0.639, lr=1.96e-5]Training steps:   8%|▊         | 15/200 [01:36<17:06,  5.55s/it, grad_norm=1.24, loss=0.437, lr=1.95e-5]Training steps:   8%|▊         | 16/200 [01:41<16:46,  5.47s/it, grad_norm=1.24, loss=0.437, lr=1.95e-5]Training steps:   8%|▊         | 16/200 [01:41<16:46,  5.47s/it, grad_norm=1.69, loss=0.649, lr=1.95e-5]02/03/2025 15:41:37 - INFO - trainer - Memory after epoch 8: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   8%|▊         | 17/200 [01:46<16:48,  5.51s/it, grad_norm=1.7, loss=0.649, lr=1.95e-5]Training steps:   8%|▊         | 17/200 [01:46<16:48,  5.51s/it, grad_norm=1.95, loss=0.886, lr=1.94e-5]Training steps:   9%|▉         | 18/200 [01:51<16:32,  5.45s/it, grad_norm=1.95, loss=0.886, lr=1.94e-5]Training steps:   9%|▉         | 18/200 [01:51<16:32,  5.45s/it, grad_norm=1.55, loss=0.747, lr=1.94e-5]02/03/2025 15:41:46 - INFO - trainer - Memory after epoch 9: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:   8%|▊         | 17/200 [01:47<16:56,  5.55s/it, grad_norm=1.69, loss=0.649, lr=1.95e-5]Training steps:   8%|▊         | 17/200 [01:47<16:56,  5.55s/it, grad_norm=1.95, loss=0.886, lr=1.94e-5]Training steps:   9%|▉         | 18/200 [01:53<16:36,  5.47s/it, grad_norm=1.95, loss=0.886, lr=1.94e-5]Training steps:   9%|▉         | 18/200 [01:53<16:36,  5.47s/it, grad_norm=1.55, loss=0.747, lr=1.94e-5]02/03/2025 15:41:48 - INFO - trainer - Memory after epoch 9: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  10%|▉         | 19/200 [01:57<16:38,  5.52s/it, grad_norm=1.55, loss=0.747, lr=1.94e-5]Training steps:  10%|▉         | 19/200 [01:57<16:38,  5.52s/it, grad_norm=0.962, loss=0.251, lr=1.94e-5]Training steps:  10%|█         | 20/200 [02:02<16:22,  5.46s/it, grad_norm=0.962, loss=0.251, lr=1.94e-5]Training steps:  10%|█         | 20/200 [02:02<16:22,  5.46s/it, grad_norm=1.01, loss=0.229, lr=1.93e-5] 02/03/2025 15:41:57 - INFO - trainer - Memory after epoch 10: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  10%|▉         | 19/200 [01:58<16:43,  5.54s/it, grad_norm=1.55, loss=0.747, lr=1.94e-5]Training steps:  10%|▉         | 19/200 [01:58<16:43,  5.54s/it, grad_norm=0.964, loss=0.251, lr=1.94e-5]Training steps:  10%|█         | 20/200 [02:04<16:24,  5.47s/it, grad_norm=0.964, loss=0.251, lr=1.94e-5]Training steps:  10%|█         | 20/200 [02:04<16:24,  5.47s/it, grad_norm=1.01, loss=0.229, lr=1.93e-5] 02/03/2025 15:41:59 - INFO - trainer - Memory after epoch 10: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  10%|█         | 21/200 [02:08<16:26,  5.51s/it, grad_norm=1.01, loss=0.229, lr=1.93e-5]Training steps:  10%|█         | 21/200 [02:08<16:26,  5.51s/it, grad_norm=2.85, loss=0.649, lr=1.93e-5]Training steps:  11%|█         | 22/200 [02:13<16:10,  5.45s/it, grad_norm=2.85, loss=0.649, lr=1.93e-5]Training steps:  11%|█         | 22/200 [02:13<16:10,  5.45s/it, grad_norm=0.756, loss=0.234, lr=1.92e-5]02/03/2025 15:42:08 - INFO - trainer - Memory after epoch 11: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  10%|█         | 21/200 [02:09<16:24,  5.50s/it, grad_norm=1.01, loss=0.229, lr=1.93e-5]Training steps:  10%|█         | 21/200 [02:09<16:24,  5.50s/it, grad_norm=2.85, loss=0.649, lr=1.93e-5]Training steps:  11%|█         | 22/200 [02:14<16:08,  5.44s/it, grad_norm=2.85, loss=0.649, lr=1.93e-5]Training steps:  11%|█         | 22/200 [02:14<16:08,  5.44s/it, grad_norm=0.756, loss=0.234, lr=1.92e-5]02/03/2025 15:42:10 - INFO - trainer - Memory after epoch 11: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  12%|█▏        | 23/200 [02:19<16:14,  5.50s/it, grad_norm=0.756, loss=0.234, lr=1.92e-5]Training steps:  12%|█▏        | 23/200 [02:19<16:14,  5.50s/it, grad_norm=2.74, loss=0.637, lr=1.92e-5] Training steps:  12%|█▏        | 24/200 [02:24<15:59,  5.45s/it, grad_norm=2.74, loss=0.637, lr=1.92e-5]Training steps:  12%|█▏        | 24/200 [02:24<15:59,  5.45s/it, grad_norm=0.859, loss=0.218, lr=1.92e-5]02/03/2025 15:42:19 - INFO - trainer - Memory after epoch 12: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  12%|█▏        | 23/200 [02:20<16:16,  5.52s/it, grad_norm=0.756, loss=0.234, lr=1.92e-5]Training steps:  12%|█▏        | 23/200 [02:20<16:16,  5.52s/it, grad_norm=2.74, loss=0.637, lr=1.92e-5] Training steps:  12%|█▏        | 24/200 [02:25<15:58,  5.45s/it, grad_norm=2.74, loss=0.637, lr=1.92e-5]Training steps:  12%|█▏        | 24/200 [02:25<15:58,  5.45s/it, grad_norm=0.859, loss=0.218, lr=1.92e-5]02/03/2025 15:42:21 - INFO - trainer - Memory after epoch 12: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  12%|█▎        | 25/200 [02:30<16:06,  5.52s/it, grad_norm=0.859, loss=0.218, lr=1.92e-5]Training steps:  12%|█▎        | 25/200 [02:30<16:06,  5.52s/it, grad_norm=0.753, loss=0.273, lr=1.91e-5]Training steps:  13%|█▎        | 26/200 [02:35<15:49,  5.46s/it, grad_norm=0.753, loss=0.273, lr=1.91e-5]Training steps:  13%|█▎        | 26/200 [02:35<15:49,  5.46s/it, grad_norm=0.789, loss=0.488, lr=1.91e-5]02/03/2025 15:42:30 - INFO - trainer - Memory after epoch 13: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  12%|█▎        | 25/200 [02:31<16:01,  5.50s/it, grad_norm=0.859, loss=0.218, lr=1.92e-5]Training steps:  12%|█▎        | 25/200 [02:31<16:01,  5.50s/it, grad_norm=0.753, loss=0.273, lr=1.91e-5]Training steps:  13%|█▎        | 26/200 [02:36<15:45,  5.44s/it, grad_norm=0.753, loss=0.273, lr=1.91e-5]Training steps:  13%|█▎        | 26/200 [02:36<15:45,  5.44s/it, grad_norm=0.79, loss=0.488, lr=1.91e-5] 02/03/2025 15:42:32 - INFO - trainer - Memory after epoch 13: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  14%|█▎        | 27/200 [02:41<15:58,  5.54s/it, grad_norm=0.789, loss=0.488, lr=1.91e-5]Training steps:  14%|█▎        | 27/200 [02:41<15:58,  5.54s/it, grad_norm=0.919, loss=0.234, lr=1.9e-5] Training steps:  14%|█▍        | 28/200 [02:46<15:41,  5.47s/it, grad_norm=0.919, loss=0.234, lr=1.9e-5]Training steps:  14%|█▍        | 28/200 [02:46<15:41,  5.47s/it, grad_norm=0.993, loss=0.32, lr=1.9e-5] 02/03/2025 15:42:41 - INFO - trainer - Memory after epoch 14: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  14%|█▎        | 27/200 [02:42<15:55,  5.52s/it, grad_norm=0.79, loss=0.488, lr=1.91e-5]Training steps:  14%|█▎        | 27/200 [02:42<15:55,  5.52s/it, grad_norm=0.919, loss=0.234, lr=1.9e-5]Training steps:  14%|█▍        | 28/200 [02:47<15:37,  5.45s/it, grad_norm=0.919, loss=0.234, lr=1.9e-5]Training steps:  14%|█▍        | 28/200 [02:47<15:37,  5.45s/it, grad_norm=0.992, loss=0.32, lr=1.9e-5] 02/03/2025 15:42:43 - INFO - trainer - Memory after epoch 14: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  14%|█▍        | 29/200 [02:52<15:48,  5.54s/it, grad_norm=0.993, loss=0.32, lr=1.9e-5]Training steps:  14%|█▍        | 29/200 [02:52<15:48,  5.54s/it, grad_norm=0.883, loss=0.371, lr=1.9e-5]Training steps:  15%|█▌        | 30/200 [02:57<15:30,  5.48s/it, grad_norm=0.883, loss=0.371, lr=1.9e-5]Training steps:  15%|█▌        | 30/200 [02:57<15:30,  5.48s/it, grad_norm=0.55, loss=0.221, lr=1.89e-5]02/03/2025 15:42:52 - INFO - trainer - Memory after epoch 15: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  14%|█▍        | 29/200 [02:53<15:45,  5.53s/it, grad_norm=0.992, loss=0.32, lr=1.9e-5]Training steps:  14%|█▍        | 29/200 [02:53<15:45,  5.53s/it, grad_norm=0.883, loss=0.371, lr=1.9e-5]Training steps:  15%|█▌        | 30/200 [02:58<15:28,  5.46s/it, grad_norm=0.883, loss=0.371, lr=1.9e-5]Training steps:  15%|█▌        | 30/200 [02:58<15:28,  5.46s/it, grad_norm=0.55, loss=0.221, lr=1.89e-5]02/03/2025 15:42:54 - INFO - trainer - Memory after epoch 15: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  16%|█▌        | 31/200 [03:03<15:37,  5.55s/it, grad_norm=0.55, loss=0.221, lr=1.89e-5]Training steps:  16%|█▌        | 31/200 [03:03<15:37,  5.55s/it, grad_norm=1.2, loss=0.64, lr=1.89e-5]  Training steps:  16%|█▌        | 32/200 [03:08<15:20,  5.48s/it, grad_norm=1.2, loss=0.64, lr=1.89e-5]Training steps:  16%|█▌        | 32/200 [03:08<15:20,  5.48s/it, grad_norm=1.1, loss=0.529, lr=1.88e-5]02/03/2025 15:43:03 - INFO - trainer - Memory after epoch 16: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  16%|█▌        | 31/200 [03:04<15:35,  5.54s/it, grad_norm=0.55, loss=0.221, lr=1.89e-5]Training steps:  16%|█▌        | 31/200 [03:04<15:35,  5.54s/it, grad_norm=1.21, loss=0.641, lr=1.89e-5]Training steps:  16%|█▌        | 32/200 [03:09<15:17,  5.46s/it, grad_norm=1.21, loss=0.641, lr=1.89e-5]Training steps:  16%|█▌        | 32/200 [03:09<15:17,  5.46s/it, grad_norm=1.1, loss=0.53, lr=1.88e-5]  02/03/2025 15:43:05 - INFO - trainer - Memory after epoch 16: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  16%|█▋        | 33/200 [03:14<15:25,  5.54s/it, grad_norm=1.1, loss=0.529, lr=1.88e-5]Training steps:  16%|█▋        | 33/200 [03:14<15:25,  5.54s/it, grad_norm=1.22, loss=0.505, lr=1.88e-5]Training steps:  17%|█▋        | 34/200 [03:20<15:09,  5.48s/it, grad_norm=1.22, loss=0.505, lr=1.88e-5]Training steps:  17%|█▋        | 34/200 [03:20<15:09,  5.48s/it, grad_norm=1.13, loss=0.234, lr=1.88e-5]02/03/2025 15:43:14 - INFO - trainer - Memory after epoch 17: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  16%|█▋        | 33/200 [03:15<15:20,  5.51s/it, grad_norm=1.1, loss=0.53, lr=1.88e-5]Training steps:  16%|█▋        | 33/200 [03:15<15:20,  5.51s/it, grad_norm=1.22, loss=0.505, lr=1.88e-5]Training steps:  17%|█▋        | 34/200 [03:20<15:05,  5.45s/it, grad_norm=1.22, loss=0.505, lr=1.88e-5]Training steps:  17%|█▋        | 34/200 [03:20<15:05,  5.45s/it, grad_norm=1.13, loss=0.234, lr=1.88e-5]02/03/2025 15:43:16 - INFO - trainer - Memory after epoch 17: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  18%|█▊        | 35/200 [03:25<15:13,  5.54s/it, grad_norm=1.13, loss=0.234, lr=1.88e-5]Training steps:  18%|█▊        | 35/200 [03:25<15:13,  5.54s/it, grad_norm=1.04, loss=0.267, lr=1.87e-5]wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
Training steps:  18%|█▊        | 36/200 [03:30<14:57,  5.47s/it, grad_norm=1.04, loss=0.267, lr=1.87e-5]Training steps:  18%|█▊        | 36/200 [03:30<14:57,  5.47s/it, grad_norm=1.18, loss=0.37, lr=1.87e-5] 02/03/2025 15:43:25 - INFO - trainer - Memory after epoch 18: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  18%|█▊        | 35/200 [03:26<15:11,  5.52s/it, grad_norm=1.13, loss=0.234, lr=1.88e-5]Training steps:  18%|█▊        | 35/200 [03:26<15:11,  5.52s/it, grad_norm=1.04, loss=0.267, lr=1.87e-5]Training steps:  18%|█▊        | 36/200 [03:31<14:54,  5.46s/it, grad_norm=1.04, loss=0.267, lr=1.87e-5]Training steps:  18%|█▊        | 36/200 [03:31<14:54,  5.46s/it, grad_norm=1.18, loss=0.37, lr=1.87e-5] 02/03/2025 15:43:27 - INFO - trainer - Memory after epoch 18: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  18%|█▊        | 37/200 [03:36<15:04,  5.55s/it, grad_norm=1.18, loss=0.37, lr=1.87e-5]Training steps:  18%|█▊        | 37/200 [03:36<15:04,  5.55s/it, grad_norm=0.573, loss=0.193, lr=1.86e-5]Training steps:  19%|█▉        | 38/200 [03:42<14:47,  5.48s/it, grad_norm=0.573, loss=0.193, lr=1.86e-5]Training steps:  19%|█▉        | 38/200 [03:42<14:47,  5.48s/it, grad_norm=0.84, loss=0.373, lr=1.86e-5] 02/03/2025 15:43:36 - INFO - trainer - Memory after epoch 19: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  18%|█▊        | 37/200 [03:37<15:02,  5.54s/it, grad_norm=1.18, loss=0.37, lr=1.87e-5]Training steps:  18%|█▊        | 37/200 [03:37<15:02,  5.54s/it, grad_norm=0.573, loss=0.193, lr=1.86e-5]Training steps:  19%|█▉        | 38/200 [03:42<14:46,  5.47s/it, grad_norm=0.573, loss=0.193, lr=1.86e-5]Training steps:  19%|█▉        | 38/200 [03:42<14:46,  5.47s/it, grad_norm=0.841, loss=0.373, lr=1.86e-5]02/03/2025 15:43:38 - INFO - trainer - Memory after epoch 19: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  20%|█▉        | 39/200 [03:47<14:54,  5.55s/it, grad_norm=0.84, loss=0.373, lr=1.86e-5]Training steps:  20%|█▉        | 39/200 [03:47<14:54,  5.55s/it, grad_norm=1.22, loss=0.244, lr=1.86e-5]Training steps:  20%|██        | 40/200 [03:53<14:37,  5.49s/it, grad_norm=1.22, loss=0.244, lr=1.86e-5]Training steps:  20%|██        | 40/200 [03:53<14:37,  5.49s/it, grad_norm=1.26, loss=0.381, lr=1.85e-5]02/03/2025 15:43:47 - INFO - trainer - Memory after epoch 20: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  20%|█▉        | 39/200 [03:48<14:55,  5.56s/it, grad_norm=0.841, loss=0.373, lr=1.86e-5]Training steps:  20%|█▉        | 39/200 [03:48<14:55,  5.56s/it, grad_norm=1.21, loss=0.244, lr=1.86e-5] Training steps:  20%|██        | 40/200 [03:53<14:38,  5.49s/it, grad_norm=1.21, loss=0.244, lr=1.86e-5]Training steps:  20%|██        | 40/200 [03:53<14:38,  5.49s/it, grad_norm=1.26, loss=0.381, lr=1.85e-5]02/03/2025 15:43:49 - INFO - trainer - Memory after epoch 20: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  20%|██        | 41/200 [03:58<14:39,  5.53s/it, grad_norm=1.26, loss=0.381, lr=1.85e-5]Training steps:  20%|██        | 41/200 [03:58<14:39,  5.53s/it, grad_norm=1.24, loss=0.549, lr=1.85e-5]Training steps:  21%|██        | 42/200 [04:04<14:24,  5.47s/it, grad_norm=1.24, loss=0.549, lr=1.85e-5]Training steps:  21%|██        | 42/200 [04:04<14:24,  5.47s/it, grad_norm=0.865, loss=0.239, lr=1.84e-5]02/03/2025 15:43:58 - INFO - trainer - Memory after epoch 21: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  20%|██        | 41/200 [03:59<14:42,  5.55s/it, grad_norm=1.26, loss=0.381, lr=1.85e-5]Training steps:  20%|██        | 41/200 [03:59<14:42,  5.55s/it, grad_norm=1.24, loss=0.55, lr=1.85e-5] Training steps:  21%|██        | 42/200 [04:04<14:28,  5.50s/it, grad_norm=1.24, loss=0.55, lr=1.85e-5]Training steps:  21%|██        | 42/200 [04:04<14:28,  5.50s/it, grad_norm=0.865, loss=0.239, lr=1.84e-5]02/03/2025 15:44:00 - INFO - trainer - Memory after epoch 21: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  22%|██▏       | 43/200 [04:09<14:31,  5.55s/it, grad_norm=0.865, loss=0.239, lr=1.84e-5]Training steps:  22%|██▏       | 43/200 [04:09<14:31,  5.55s/it, grad_norm=0.802, loss=0.268, lr=1.84e-5]Training steps:  22%|██▏       | 44/200 [04:15<14:15,  5.48s/it, grad_norm=0.802, loss=0.268, lr=1.84e-5]Training steps:  22%|██▏       | 44/200 [04:15<14:15,  5.48s/it, grad_norm=1.73, loss=0.429, lr=1.84e-5] 02/03/2025 15:44:09 - INFO - trainer - Memory after epoch 22: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  22%|██▏       | 43/200 [04:10<14:33,  5.56s/it, grad_norm=0.865, loss=0.239, lr=1.84e-5]Training steps:  22%|██▏       | 43/200 [04:10<14:33,  5.56s/it, grad_norm=0.803, loss=0.268, lr=1.84e-5]Training steps:  22%|██▏       | 44/200 [04:15<14:15,  5.48s/it, grad_norm=0.803, loss=0.268, lr=1.84e-5]Training steps:  22%|██▏       | 44/200 [04:15<14:15,  5.48s/it, grad_norm=1.73, loss=0.429, lr=1.84e-5] 02/03/2025 15:44:11 - INFO - trainer - Memory after epoch 22: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  22%|██▎       | 45/200 [04:20<14:19,  5.54s/it, grad_norm=1.73, loss=0.429, lr=1.84e-5]Training steps:  22%|██▎       | 45/200 [04:20<14:19,  5.54s/it, grad_norm=1.52, loss=0.411, lr=1.83e-5]Training steps:  23%|██▎       | 46/200 [04:26<14:03,  5.48s/it, grad_norm=1.52, loss=0.411, lr=1.83e-5]Training steps:  23%|██▎       | 46/200 [04:26<14:03,  5.48s/it, grad_norm=1.01, loss=0.406, lr=1.83e-5]02/03/2025 15:44:20 - INFO - trainer - Memory after epoch 23: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  22%|██▎       | 45/200 [04:21<14:22,  5.56s/it, grad_norm=1.73, loss=0.429, lr=1.84e-5]Training steps:  22%|██▎       | 45/200 [04:21<14:22,  5.56s/it, grad_norm=1.52, loss=0.411, lr=1.83e-5]Training steps:  23%|██▎       | 46/200 [04:27<14:04,  5.48s/it, grad_norm=1.52, loss=0.411, lr=1.83e-5]Training steps:  23%|██▎       | 46/200 [04:27<14:04,  5.48s/it, grad_norm=1.01, loss=0.406, lr=1.83e-5]02/03/2025 15:44:22 - INFO - trainer - Memory after epoch 23: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  24%|██▎       | 47/200 [04:31<14:07,  5.54s/it, grad_norm=1.01, loss=0.406, lr=1.83e-5]Training steps:  24%|██▎       | 47/200 [04:31<14:07,  5.54s/it, grad_norm=1.31, loss=0.512, lr=1.82e-5]Training steps:  24%|██▍       | 48/200 [04:37<13:51,  5.47s/it, grad_norm=1.31, loss=0.512, lr=1.82e-5]Training steps:  24%|██▍       | 48/200 [04:37<13:51,  5.47s/it, grad_norm=0.931, loss=0.277, lr=1.82e-5]02/03/2025 15:44:31 - INFO - trainer - Memory after epoch 24: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  24%|██▎       | 47/200 [04:32<14:11,  5.56s/it, grad_norm=1.01, loss=0.406, lr=1.83e-5]Training steps:  24%|██▎       | 47/200 [04:32<14:11,  5.56s/it, grad_norm=1.31, loss=0.512, lr=1.82e-5]Training steps:  24%|██▍       | 48/200 [04:38<13:54,  5.49s/it, grad_norm=1.31, loss=0.512, lr=1.82e-5]Training steps:  24%|██▍       | 48/200 [04:38<13:54,  5.49s/it, grad_norm=0.93, loss=0.277, lr=1.82e-5]02/03/2025 15:44:33 - INFO - trainer - Memory after epoch 24: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  24%|██▍       | 49/200 [04:42<13:55,  5.54s/it, grad_norm=0.931, loss=0.277, lr=1.82e-5]Training steps:  24%|██▍       | 49/200 [04:42<13:55,  5.54s/it, grad_norm=0.71, loss=0.196, lr=1.82e-5] Training steps:  25%|██▌       | 50/200 [04:48<13:40,  5.47s/it, grad_norm=0.71, loss=0.196, lr=1.82e-5]Training steps:  25%|██▌       | 50/200 [04:48<13:40,  5.47s/it, grad_norm=2.44, loss=0.441, lr=1.81e-5]02/03/2025 15:44:42 - INFO - trainer - Memory after epoch 25: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  24%|██▍       | 49/200 [04:43<14:00,  5.57s/it, grad_norm=0.93, loss=0.277, lr=1.82e-5]Training steps:  24%|██▍       | 49/200 [04:43<14:00,  5.57s/it, grad_norm=0.71, loss=0.196, lr=1.82e-5]Training steps:  25%|██▌       | 50/200 [04:49<13:43,  5.49s/it, grad_norm=0.71, loss=0.196, lr=1.82e-5]Training steps:  25%|██▌       | 50/200 [04:49<13:43,  5.49s/it, grad_norm=2.43, loss=0.441, lr=1.81e-5]02/03/2025 15:44:44 - INFO - trainer - Memory after epoch 25: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  26%|██▌       | 51/200 [04:53<13:46,  5.55s/it, grad_norm=2.44, loss=0.441, lr=1.81e-5]Training steps:  26%|██▌       | 51/200 [04:53<13:46,  5.55s/it, grad_norm=1.08, loss=0.26, lr=1.81e-5] Training steps:  26%|██▌       | 52/200 [04:59<13:30,  5.48s/it, grad_norm=1.08, loss=0.26, lr=1.81e-5]Training steps:  26%|██▌       | 52/200 [04:59<13:30,  5.48s/it, grad_norm=0.804, loss=0.256, lr=1.8e-5]02/03/2025 15:44:53 - INFO - trainer - Memory after epoch 26: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  26%|██▌       | 51/200 [04:54<13:50,  5.57s/it, grad_norm=2.43, loss=0.441, lr=1.81e-5]Training steps:  26%|██▌       | 51/200 [04:54<13:50,  5.57s/it, grad_norm=1.08, loss=0.26, lr=1.81e-5] Training steps:  26%|██▌       | 52/200 [05:00<13:32,  5.49s/it, grad_norm=1.08, loss=0.26, lr=1.81e-5]Training steps:  26%|██▌       | 52/200 [05:00<13:32,  5.49s/it, grad_norm=0.806, loss=0.256, lr=1.8e-5]02/03/2025 15:44:55 - INFO - trainer - Memory after epoch 26: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  26%|██▋       | 53/200 [05:04<13:35,  5.55s/it, grad_norm=0.804, loss=0.256, lr=1.8e-5]Training steps:  26%|██▋       | 53/200 [05:04<13:35,  5.55s/it, grad_norm=0.98, loss=0.233, lr=1.8e-5] Training steps:  27%|██▋       | 54/200 [05:10<13:21,  5.49s/it, grad_norm=0.98, loss=0.233, lr=1.8e-5]Training steps:  27%|██▋       | 54/200 [05:10<13:21,  5.49s/it, grad_norm=0.801, loss=0.239, lr=1.8e-5]02/03/2025 15:45:05 - INFO - trainer - Memory after epoch 27: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  26%|██▋       | 53/200 [05:05<13:37,  5.56s/it, grad_norm=0.806, loss=0.256, lr=1.8e-5]Training steps:  26%|██▋       | 53/200 [05:05<13:37,  5.56s/it, grad_norm=0.978, loss=0.233, lr=1.8e-5]Training steps:  27%|██▋       | 54/200 [05:11<13:20,  5.48s/it, grad_norm=0.978, loss=0.233, lr=1.8e-5]Training steps:  27%|██▋       | 54/200 [05:11<13:20,  5.48s/it, grad_norm=0.8, loss=0.239, lr=1.8e-5]  02/03/2025 15:45:06 - INFO - trainer - Memory after epoch 27: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  28%|██▊       | 55/200 [05:15<13:27,  5.57s/it, grad_norm=0.801, loss=0.239, lr=1.8e-5]Training steps:  28%|██▊       | 55/200 [05:15<13:27,  5.57s/it, grad_norm=0.857, loss=0.254, lr=1.79e-5]Training steps:  28%|██▊       | 56/200 [05:21<13:13,  5.51s/it, grad_norm=0.857, loss=0.254, lr=1.79e-5]Training steps:  28%|██▊       | 56/200 [05:21<13:13,  5.51s/it, grad_norm=2.05, loss=0.585, lr=1.79e-5] 02/03/2025 15:45:16 - INFO - trainer - Memory after epoch 28: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  28%|██▊       | 55/200 [05:16<13:22,  5.53s/it, grad_norm=0.8, loss=0.239, lr=1.8e-5]Training steps:  28%|██▊       | 55/200 [05:16<13:22,  5.53s/it, grad_norm=0.858, loss=0.254, lr=1.79e-5]Training steps:  28%|██▊       | 56/200 [05:22<13:07,  5.47s/it, grad_norm=0.858, loss=0.254, lr=1.79e-5]Training steps:  28%|██▊       | 56/200 [05:22<13:07,  5.47s/it, grad_norm=2.04, loss=0.585, lr=1.79e-5] 02/03/2025 15:45:17 - INFO - trainer - Memory after epoch 28: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  28%|██▊       | 57/200 [05:27<13:18,  5.58s/it, grad_norm=2.05, loss=0.585, lr=1.79e-5]Training steps:  28%|██▊       | 57/200 [05:27<13:18,  5.58s/it, grad_norm=0.912, loss=0.211, lr=1.78e-5]Training steps:  29%|██▉       | 58/200 [05:32<13:02,  5.51s/it, grad_norm=0.912, loss=0.211, lr=1.78e-5]Training steps:  29%|██▉       | 58/200 [05:32<13:02,  5.51s/it, grad_norm=1.71, loss=0.506, lr=1.78e-5] 02/03/2025 15:45:27 - INFO - trainer - Memory after epoch 29: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  28%|██▊       | 57/200 [05:27<13:09,  5.52s/it, grad_norm=2.04, loss=0.585, lr=1.79e-5]Training steps:  28%|██▊       | 57/200 [05:27<13:09,  5.52s/it, grad_norm=0.913, loss=0.211, lr=1.78e-5]Training steps:  29%|██▉       | 58/200 [05:33<12:55,  5.46s/it, grad_norm=0.913, loss=0.211, lr=1.78e-5]Training steps:  29%|██▉       | 58/200 [05:33<12:55,  5.46s/it, grad_norm=1.71, loss=0.506, lr=1.78e-5] 02/03/2025 15:45:28 - INFO - trainer - Memory after epoch 29: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  30%|██▉       | 59/200 [05:38<13:05,  5.57s/it, grad_norm=1.71, loss=0.506, lr=1.78e-5]Training steps:  30%|██▉       | 59/200 [05:38<13:05,  5.57s/it, grad_norm=1.09, loss=0.217, lr=1.78e-5]Training steps:  30%|███       | 60/200 [05:43<12:49,  5.49s/it, grad_norm=1.09, loss=0.217, lr=1.78e-5]Training steps:  30%|███       | 60/200 [05:43<12:49,  5.49s/it, grad_norm=1.89, loss=0.42, lr=1.77e-5] 02/03/2025 15:45:38 - INFO - trainer - Memory after epoch 30: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  30%|██▉       | 59/200 [05:38<12:58,  5.52s/it, grad_norm=1.71, loss=0.506, lr=1.78e-5]Training steps:  30%|██▉       | 59/200 [05:38<12:58,  5.52s/it, grad_norm=1.09, loss=0.217, lr=1.78e-5]Training steps:  30%|███       | 60/200 [05:44<12:43,  5.46s/it, grad_norm=1.09, loss=0.217, lr=1.78e-5]Training steps:  30%|███       | 60/200 [05:44<12:43,  5.46s/it, grad_norm=1.88, loss=0.42, lr=1.77e-5] 02/03/2025 15:45:39 - INFO - trainer - Memory after epoch 30: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  30%|███       | 61/200 [05:49<12:52,  5.56s/it, grad_norm=1.89, loss=0.42, lr=1.77e-5]Training steps:  30%|███       | 61/200 [05:49<12:52,  5.56s/it, grad_norm=0.779, loss=0.26, lr=1.77e-5]Training steps:  31%|███       | 62/200 [05:54<12:37,  5.49s/it, grad_norm=0.779, loss=0.26, lr=1.77e-5]Training steps:  31%|███       | 62/200 [05:54<12:37,  5.49s/it, grad_norm=0.706, loss=0.187, lr=1.76e-5]02/03/2025 15:45:49 - INFO - trainer - Memory after epoch 31: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  30%|███       | 61/200 [05:49<12:51,  5.55s/it, grad_norm=1.88, loss=0.42, lr=1.77e-5]Training steps:  30%|███       | 61/200 [05:49<12:51,  5.55s/it, grad_norm=0.777, loss=0.26, lr=1.77e-5]Training steps:  31%|███       | 62/200 [05:55<12:35,  5.48s/it, grad_norm=0.777, loss=0.26, lr=1.77e-5]Training steps:  31%|███       | 62/200 [05:55<12:35,  5.48s/it, grad_norm=0.705, loss=0.187, lr=1.76e-5]02/03/2025 15:45:50 - INFO - trainer - Memory after epoch 31: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  32%|███▏      | 63/200 [06:00<12:42,  5.56s/it, grad_norm=0.706, loss=0.187, lr=1.76e-5]Training steps:  32%|███▏      | 63/200 [06:00<12:42,  5.56s/it, grad_norm=0.979, loss=0.285, lr=1.76e-5]Training steps:  32%|███▏      | 64/200 [06:05<12:26,  5.49s/it, grad_norm=0.979, loss=0.285, lr=1.76e-5]Training steps:  32%|███▏      | 64/200 [06:05<12:26,  5.49s/it, grad_norm=1.17, loss=0.328, lr=1.76e-5] 02/03/2025 15:46:00 - INFO - trainer - Memory after epoch 32: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  32%|███▏      | 63/200 [06:00<12:38,  5.54s/it, grad_norm=0.705, loss=0.187, lr=1.76e-5]Training steps:  32%|███▏      | 63/200 [06:00<12:38,  5.54s/it, grad_norm=0.979, loss=0.285, lr=1.76e-5]Training steps:  32%|███▏      | 64/200 [06:06<12:23,  5.47s/it, grad_norm=0.979, loss=0.285, lr=1.76e-5]Training steps:  32%|███▏      | 64/200 [06:06<12:23,  5.47s/it, grad_norm=1.17, loss=0.328, lr=1.76e-5] 02/03/2025 15:46:01 - INFO - trainer - Memory after epoch 32: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  32%|███▎      | 65/200 [06:11<12:29,  5.55s/it, grad_norm=1.17, loss=0.328, lr=1.76e-5]Training steps:  32%|███▎      | 65/200 [06:11<12:29,  5.55s/it, grad_norm=0.819, loss=0.231, lr=1.75e-5]Training steps:  33%|███▎      | 66/200 [06:16<12:14,  5.48s/it, grad_norm=0.819, loss=0.231, lr=1.75e-5]Training steps:  33%|███▎      | 66/200 [06:16<12:14,  5.48s/it, grad_norm=0.732, loss=0.198, lr=1.75e-5]02/03/2025 15:46:11 - INFO - trainer - Memory after epoch 33: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  32%|███▎      | 65/200 [06:11<12:27,  5.54s/it, grad_norm=1.17, loss=0.328, lr=1.76e-5]Training steps:  32%|███▎      | 65/200 [06:11<12:27,  5.54s/it, grad_norm=0.818, loss=0.231, lr=1.75e-5]Training steps:  33%|███▎      | 66/200 [06:17<12:12,  5.47s/it, grad_norm=0.818, loss=0.231, lr=1.75e-5]Training steps:  33%|███▎      | 66/200 [06:17<12:12,  5.47s/it, grad_norm=0.729, loss=0.198, lr=1.75e-5]02/03/2025 15:46:12 - INFO - trainer - Memory after epoch 33: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  34%|███▎      | 67/200 [06:22<12:19,  5.56s/it, grad_norm=0.732, loss=0.198, lr=1.75e-5]Training steps:  34%|███▎      | 67/200 [06:22<12:19,  5.56s/it, grad_norm=1.28, loss=0.297, lr=1.74e-5] Training steps:  34%|███▍      | 68/200 [06:27<12:04,  5.49s/it, grad_norm=1.28, loss=0.297, lr=1.74e-5]Training steps:  34%|███▍      | 68/200 [06:27<12:04,  5.49s/it, grad_norm=2.23, loss=0.449, lr=1.74e-5]02/03/2025 15:46:22 - INFO - trainer - Memory after epoch 34: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  34%|███▎      | 67/200 [06:22<12:15,  5.53s/it, grad_norm=0.729, loss=0.198, lr=1.75e-5]Training steps:  34%|███▎      | 67/200 [06:22<12:15,  5.53s/it, grad_norm=1.29, loss=0.298, lr=1.74e-5] Training steps:  34%|███▍      | 68/200 [06:28<12:01,  5.47s/it, grad_norm=1.29, loss=0.298, lr=1.74e-5]Training steps:  34%|███▍      | 68/200 [06:28<12:01,  5.47s/it, grad_norm=2.23, loss=0.449, lr=1.74e-5]02/03/2025 15:46:23 - INFO - trainer - Memory after epoch 34: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  34%|███▍      | 69/200 [06:33<12:06,  5.54s/it, grad_norm=2.23, loss=0.449, lr=1.74e-5]Training steps:  34%|███▍      | 69/200 [06:33<12:06,  5.54s/it, grad_norm=1.05, loss=0.249, lr=1.73e-5]Training steps:  35%|███▌      | 70/200 [06:38<11:52,  5.48s/it, grad_norm=1.05, loss=0.249, lr=1.73e-5]Training steps:  35%|███▌      | 70/200 [06:38<11:52,  5.48s/it, grad_norm=0.773, loss=0.249, lr=1.73e-5]02/03/2025 15:46:33 - INFO - trainer - Memory after epoch 35: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  34%|███▍      | 69/200 [06:33<12:04,  5.53s/it, grad_norm=2.23, loss=0.449, lr=1.74e-5]Training steps:  34%|███▍      | 69/200 [06:33<12:04,  5.53s/it, grad_norm=1.05, loss=0.249, lr=1.73e-5]Training steps:  35%|███▌      | 70/200 [06:39<11:50,  5.46s/it, grad_norm=1.05, loss=0.249, lr=1.73e-5]Training steps:  35%|███▌      | 70/200 [06:39<11:50,  5.46s/it, grad_norm=0.771, loss=0.249, lr=1.73e-5]02/03/2025 15:46:34 - INFO - trainer - Memory after epoch 35: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  36%|███▌      | 71/200 [06:44<11:55,  5.55s/it, grad_norm=0.773, loss=0.249, lr=1.73e-5]Training steps:  36%|███▌      | 71/200 [06:44<11:55,  5.55s/it, grad_norm=0.594, loss=0.219, lr=1.73e-5]Training steps:  36%|███▌      | 72/200 [06:49<11:42,  5.49s/it, grad_norm=0.594, loss=0.219, lr=1.73e-5]Training steps:  36%|███▌      | 72/200 [06:49<11:42,  5.49s/it, grad_norm=0.781, loss=0.213, lr=1.72e-5]02/03/2025 15:46:44 - INFO - trainer - Memory after epoch 36: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  36%|███▌      | 71/200 [06:44<11:51,  5.52s/it, grad_norm=0.771, loss=0.249, lr=1.73e-5]Training steps:  36%|███▌      | 71/200 [06:44<11:51,  5.52s/it, grad_norm=0.593, loss=0.219, lr=1.73e-5]Training steps:  36%|███▌      | 72/200 [06:50<11:40,  5.48s/it, grad_norm=0.593, loss=0.219, lr=1.73e-5]Training steps:  36%|███▌      | 72/200 [06:50<11:40,  5.48s/it, grad_norm=0.783, loss=0.213, lr=1.72e-5]02/03/2025 15:46:45 - INFO - trainer - Memory after epoch 36: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  36%|███▋      | 73/200 [06:55<11:44,  5.55s/it, grad_norm=0.781, loss=0.213, lr=1.72e-5]Training steps:  36%|███▋      | 73/200 [06:55<11:44,  5.55s/it, grad_norm=0.525, loss=0.2, lr=1.72e-5]  Training steps:  37%|███▋      | 74/200 [07:00<11:31,  5.49s/it, grad_norm=0.525, loss=0.2, lr=1.72e-5]Training steps:  37%|███▋      | 74/200 [07:00<11:31,  5.49s/it, grad_norm=1.14, loss=0.262, lr=1.71e-5]02/03/2025 15:46:55 - INFO - trainer - Memory after epoch 37: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  36%|███▋      | 73/200 [06:55<11:46,  5.56s/it, grad_norm=0.783, loss=0.213, lr=1.72e-5]Training steps:  36%|███▋      | 73/200 [06:55<11:46,  5.56s/it, grad_norm=0.526, loss=0.2, lr=1.72e-5]  Training steps:  37%|███▋      | 74/200 [07:01<11:31,  5.49s/it, grad_norm=0.526, loss=0.2, lr=1.72e-5]Training steps:  37%|███▋      | 74/200 [07:01<11:31,  5.49s/it, grad_norm=1.14, loss=0.262, lr=1.71e-5]02/03/2025 15:46:56 - INFO - trainer - Memory after epoch 37: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  38%|███▊      | 75/200 [07:06<11:33,  5.55s/it, grad_norm=1.14, loss=0.262, lr=1.71e-5]Training steps:  38%|███▊      | 75/200 [07:06<11:33,  5.55s/it, grad_norm=0.815, loss=0.203, lr=1.71e-5]Training steps:  38%|███▊      | 76/200 [07:11<11:19,  5.48s/it, grad_norm=0.815, loss=0.203, lr=1.71e-5]Training steps:  38%|███▊      | 76/200 [07:11<11:19,  5.48s/it, grad_norm=1.12, loss=0.296, lr=1.71e-5] 02/03/2025 15:47:06 - INFO - trainer - Memory after epoch 38: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  38%|███▊      | 75/200 [07:06<11:32,  5.54s/it, grad_norm=1.14, loss=0.262, lr=1.71e-5]Training steps:  38%|███▊      | 75/200 [07:06<11:32,  5.54s/it, grad_norm=0.815, loss=0.203, lr=1.71e-5]Training steps:  38%|███▊      | 76/200 [07:12<11:18,  5.47s/it, grad_norm=0.815, loss=0.203, lr=1.71e-5]Training steps:  38%|███▊      | 76/200 [07:12<11:18,  5.47s/it, grad_norm=1.11, loss=0.295, lr=1.71e-5] 02/03/2025 15:47:07 - INFO - trainer - Memory after epoch 38: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
Training steps:  38%|███▊      | 77/200 [07:17<11:23,  5.55s/it, grad_norm=1.12, loss=0.296, lr=1.71e-5]Training steps:  38%|███▊      | 77/200 [07:17<11:23,  5.55s/it, grad_norm=0.824, loss=0.238, lr=1.7e-5]Training steps:  39%|███▉      | 78/200 [07:22<11:09,  5.48s/it, grad_norm=0.824, loss=0.238, lr=1.7e-5]Training steps:  39%|███▉      | 78/200 [07:22<11:09,  5.48s/it, grad_norm=1.04, loss=0.214, lr=1.7e-5] 02/03/2025 15:47:17 - INFO - trainer - Memory after epoch 39: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  38%|███▊      | 77/200 [07:17<11:20,  5.53s/it, grad_norm=1.11, loss=0.295, lr=1.71e-5]Training steps:  38%|███▊      | 77/200 [07:17<11:20,  5.53s/it, grad_norm=0.826, loss=0.238, lr=1.7e-5]Training steps:  39%|███▉      | 78/200 [07:23<11:06,  5.46s/it, grad_norm=0.826, loss=0.238, lr=1.7e-5]Training steps:  39%|███▉      | 78/200 [07:23<11:06,  5.46s/it, grad_norm=1.04, loss=0.214, lr=1.7e-5] 02/03/2025 15:47:18 - INFO - trainer - Memory after epoch 39: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  40%|███▉      | 79/200 [07:28<11:12,  5.56s/it, grad_norm=1.04, loss=0.214, lr=1.7e-5]Training steps:  40%|███▉      | 79/200 [07:28<11:12,  5.56s/it, grad_norm=1.64, loss=0.378, lr=1.69e-5]Training steps:  40%|████      | 80/200 [07:33<10:59,  5.49s/it, grad_norm=1.64, loss=0.378, lr=1.69e-5]Training steps:  40%|████      | 80/200 [07:33<10:59,  5.49s/it, grad_norm=0.757, loss=0.249, lr=1.69e-5]02/03/2025 15:47:28 - INFO - trainer - Memory after epoch 40: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  40%|███▉      | 79/200 [07:28<11:06,  5.51s/it, grad_norm=1.04, loss=0.214, lr=1.7e-5]Training steps:  40%|███▉      | 79/200 [07:28<11:06,  5.51s/it, grad_norm=1.64, loss=0.378, lr=1.69e-5]Training steps:  40%|████      | 80/200 [07:34<10:53,  5.45s/it, grad_norm=1.64, loss=0.378, lr=1.69e-5]Training steps:  40%|████      | 80/200 [07:34<10:53,  5.45s/it, grad_norm=0.757, loss=0.249, lr=1.69e-5]02/03/2025 15:47:29 - INFO - trainer - Memory after epoch 40: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  40%|████      | 81/200 [07:39<11:01,  5.56s/it, grad_norm=0.757, loss=0.249, lr=1.69e-5]Training steps:  40%|████      | 81/200 [07:39<11:01,  5.56s/it, grad_norm=0.941, loss=0.21, lr=1.69e-5] Training steps:  41%|████      | 82/200 [07:44<10:47,  5.49s/it, grad_norm=0.941, loss=0.21, lr=1.69e-5]Training steps:  41%|████      | 82/200 [07:44<10:47,  5.49s/it, grad_norm=1.43, loss=0.363, lr=1.68e-5]02/03/2025 15:47:39 - INFO - trainer - Memory after epoch 41: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  40%|████      | 81/200 [07:39<10:57,  5.53s/it, grad_norm=0.757, loss=0.249, lr=1.69e-5]Training steps:  40%|████      | 81/200 [07:39<10:57,  5.53s/it, grad_norm=0.944, loss=0.21, lr=1.69e-5] Training steps:  41%|████      | 82/200 [07:45<10:44,  5.46s/it, grad_norm=0.944, loss=0.21, lr=1.69e-5]Training steps:  41%|████      | 82/200 [07:45<10:44,  5.46s/it, grad_norm=1.43, loss=0.363, lr=1.68e-5]02/03/2025 15:47:40 - INFO - trainer - Memory after epoch 41: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  42%|████▏     | 83/200 [07:50<10:50,  5.56s/it, grad_norm=1.43, loss=0.363, lr=1.68e-5]Training steps:  42%|████▏     | 83/200 [07:50<10:50,  5.56s/it, grad_norm=2.7, loss=0.758, lr=1.68e-5] Training steps:  42%|████▏     | 84/200 [07:55<10:36,  5.49s/it, grad_norm=2.7, loss=0.758, lr=1.68e-5]Training steps:  42%|████▏     | 84/200 [07:55<10:36,  5.49s/it, grad_norm=0.625, loss=0.204, lr=1.67e-5]02/03/2025 15:47:50 - INFO - trainer - Memory after epoch 42: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  42%|████▏     | 83/200 [07:50<10:48,  5.54s/it, grad_norm=1.43, loss=0.363, lr=1.68e-5]Training steps:  42%|████▏     | 83/200 [07:50<10:48,  5.54s/it, grad_norm=2.7, loss=0.757, lr=1.68e-5] Training steps:  42%|████▏     | 84/200 [07:56<10:34,  5.47s/it, grad_norm=2.7, loss=0.757, lr=1.68e-5]Training steps:  42%|████▏     | 84/200 [07:56<10:34,  5.47s/it, grad_norm=0.625, loss=0.204, lr=1.67e-5]02/03/2025 15:47:51 - INFO - trainer - Memory after epoch 42: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  42%|████▎     | 85/200 [08:01<10:37,  5.54s/it, grad_norm=0.625, loss=0.204, lr=1.67e-5]Training steps:  42%|████▎     | 85/200 [08:01<10:37,  5.54s/it, grad_norm=2.64, loss=0.52, lr=1.67e-5]  Training steps:  43%|████▎     | 86/200 [08:06<10:24,  5.48s/it, grad_norm=2.64, loss=0.52, lr=1.67e-5]Training steps:  43%|████▎     | 86/200 [08:06<10:24,  5.48s/it, grad_norm=1.48, loss=0.457, lr=1.67e-5]02/03/2025 15:48:01 - INFO - trainer - Memory after epoch 43: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  42%|████▎     | 85/200 [08:01<10:36,  5.54s/it, grad_norm=0.625, loss=0.204, lr=1.67e-5]Training steps:  42%|████▎     | 85/200 [08:01<10:36,  5.54s/it, grad_norm=2.64, loss=0.52, lr=1.67e-5]  Training steps:  43%|████▎     | 86/200 [08:07<10:23,  5.47s/it, grad_norm=2.64, loss=0.52, lr=1.67e-5]Training steps:  43%|████▎     | 86/200 [08:07<10:23,  5.47s/it, grad_norm=1.48, loss=0.457, lr=1.67e-5]02/03/2025 15:48:02 - INFO - trainer - Memory after epoch 43: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  44%|████▎     | 87/200 [08:12<10:26,  5.54s/it, grad_norm=1.48, loss=0.457, lr=1.67e-5]Training steps:  44%|████▎     | 87/200 [08:12<10:26,  5.54s/it, grad_norm=0.926, loss=0.244, lr=1.66e-5]Training steps:  44%|████▍     | 88/200 [08:17<10:13,  5.48s/it, grad_norm=0.926, loss=0.244, lr=1.66e-5]Training steps:  44%|████▍     | 88/200 [08:17<10:13,  5.48s/it, grad_norm=0.811, loss=0.227, lr=1.66e-5]02/03/2025 15:48:12 - INFO - trainer - Memory after epoch 44: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  44%|████▎     | 87/200 [08:12<10:24,  5.53s/it, grad_norm=1.48, loss=0.457, lr=1.67e-5]Training steps:  44%|████▎     | 87/200 [08:12<10:24,  5.53s/it, grad_norm=0.927, loss=0.244, lr=1.66e-5]Training steps:  44%|████▍     | 88/200 [08:18<10:11,  5.46s/it, grad_norm=0.927, loss=0.244, lr=1.66e-5]Training steps:  44%|████▍     | 88/200 [08:18<10:11,  5.46s/it, grad_norm=0.811, loss=0.227, lr=1.66e-5]02/03/2025 15:48:13 - INFO - trainer - Memory after epoch 44: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80

80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  44%|████▍     | 89/200 [08:23<10:16,  5.55s/it, grad_norm=0.811, loss=0.227, lr=1.66e-5]Training steps:  44%|████▍     | 89/200 [08:23<10:16,  5.55s/it, grad_norm=1.87, loss=0.404, lr=1.65e-5] Training steps:  45%|████▌     | 90/200 [08:29<10:03,  5.48s/it, grad_norm=1.87, loss=0.404, lr=1.65e-5]Training steps:  45%|████▌     | 90/200 [08:29<10:03,  5.48s/it, grad_norm=0.846, loss=0.242, lr=1.65e-5]02/03/2025 15:48:23 - INFO - trainer - Memory after epoch 45: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  44%|████▍     | 89/200 [08:23<10:14,  5.53s/it, grad_norm=0.811, loss=0.227, lr=1.66e-5]Training steps:  44%|████▍     | 89/200 [08:23<10:14,  5.53s/it, grad_norm=1.87, loss=0.404, lr=1.65e-5] Training steps:  45%|████▌     | 90/200 [08:29<10:02,  5.48s/it, grad_norm=1.87, loss=0.404, lr=1.65e-5]Training steps:  45%|████▌     | 90/200 [08:29<10:02,  5.48s/it, grad_norm=0.844, loss=0.242, lr=1.65e-5]02/03/2025 15:48:24 - INFO - trainer - Memory after epoch 45: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  46%|████▌     | 91/200 [08:34<10:04,  5.55s/it, grad_norm=0.846, loss=0.242, lr=1.65e-5]Training steps:  46%|████▌     | 91/200 [08:34<10:04,  5.55s/it, grad_norm=0.823, loss=0.234, lr=1.65e-5]Training steps:  46%|████▌     | 92/200 [08:40<09:51,  5.48s/it, grad_norm=0.823, loss=0.234, lr=1.65e-5]Training steps:  46%|████▌     | 92/200 [08:40<09:51,  5.48s/it, grad_norm=0.677, loss=0.207, lr=1.64e-5]02/03/2025 15:48:34 - INFO - trainer - Memory after epoch 46: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  46%|████▌     | 91/200 [08:34<10:03,  5.54s/it, grad_norm=0.844, loss=0.242, lr=1.65e-5]Training steps:  46%|████▌     | 91/200 [08:34<10:03,  5.54s/it, grad_norm=0.824, loss=0.234, lr=1.65e-5]Training steps:  46%|████▌     | 92/200 [08:40<09:51,  5.48s/it, grad_norm=0.824, loss=0.234, lr=1.65e-5]Training steps:  46%|████▌     | 92/200 [08:40<09:51,  5.48s/it, grad_norm=0.677, loss=0.207, lr=1.64e-5]02/03/2025 15:48:35 - INFO - trainer - Memory after epoch 46: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  46%|████▋     | 93/200 [08:45<09:51,  5.53s/it, grad_norm=0.677, loss=0.207, lr=1.64e-5]Training steps:  46%|████▋     | 93/200 [08:45<09:51,  5.53s/it, grad_norm=2.46, loss=0.602, lr=1.64e-5] wandb: WARNING Fatal error while uploading data. Some run data will not be synced, but it will still be written to disk. Use `wandb sync` at the end of the run to try uploading.
Training steps:  46%|████▋     | 93/200 [08:45<09:51,  5.52s/it, grad_norm=0.677, loss=0.207, lr=1.64e-5]Training steps:  46%|████▋     | 93/200 [08:45<09:51,  5.52s/it, grad_norm=2.47, loss=0.602, lr=1.64e-5] Training steps:  47%|████▋     | 94/200 [08:50<09:39,  5.46s/it, grad_norm=2.47, loss=0.602, lr=1.64e-5]Training steps:  47%|████▋     | 94/200 [08:50<09:39,  5.46s/it, grad_norm=3.07, loss=0.968, lr=1.63e-5]02/03/2025 15:48:45 - INFO - trainer - Memory after epoch 47: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  47%|████▋     | 94/200 [08:51<09:38,  5.46s/it, grad_norm=2.46, loss=0.602, lr=1.64e-5]Training steps:  47%|████▋     | 94/200 [08:51<09:38,  5.46s/it, grad_norm=3.06, loss=0.967, lr=1.63e-5]02/03/2025 15:48:46 - INFO - trainer - Memory after epoch 47: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  48%|████▊     | 95/200 [08:56<09:40,  5.52s/it, grad_norm=3.07, loss=0.968, lr=1.63e-5]Training steps:  48%|████▊     | 95/200 [08:56<09:40,  5.52s/it, grad_norm=1.27, loss=0.268, lr=1.63e-5]Training steps:  48%|████▊     | 96/200 [09:01<09:28,  5.46s/it, grad_norm=1.27, loss=0.268, lr=1.63e-5]Training steps:  48%|████▊     | 96/200 [09:01<09:28,  5.46s/it, grad_norm=2.55, loss=0.498, lr=1.63e-5]02/03/2025 15:48:56 - INFO - trainer - Memory after epoch 48: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  48%|████▊     | 95/200 [08:56<09:43,  5.56s/it, grad_norm=3.06, loss=0.967, lr=1.63e-5]Training steps:  48%|████▊     | 95/200 [08:56<09:43,  5.56s/it, grad_norm=1.27, loss=0.268, lr=1.63e-5]Training steps:  48%|████▊     | 96/200 [09:02<09:30,  5.48s/it, grad_norm=1.27, loss=0.268, lr=1.63e-5]Training steps:  48%|████▊     | 96/200 [09:02<09:30,  5.48s/it, grad_norm=2.56, loss=0.498, lr=1.63e-5]02/03/2025 15:48:57 - INFO - trainer - Memory after epoch 48: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  48%|████▊     | 97/200 [09:07<09:30,  5.54s/it, grad_norm=2.55, loss=0.498, lr=1.63e-5]Training steps:  48%|████▊     | 97/200 [09:07<09:30,  5.54s/it, grad_norm=3.04, loss=0.837, lr=1.62e-5]Training steps:  49%|████▉     | 98/200 [09:13<09:18,  5.48s/it, grad_norm=3.04, loss=0.837, lr=1.62e-5]Training steps:  49%|████▉     | 98/200 [09:13<09:18,  5.48s/it, grad_norm=1.03, loss=0.206, lr=1.62e-5]02/03/2025 15:49:07 - INFO - trainer - Memory after epoch 49: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  48%|████▊     | 97/200 [09:08<09:32,  5.56s/it, grad_norm=2.56, loss=0.498, lr=1.63e-5]Training steps:  48%|████▊     | 97/200 [09:08<09:32,  5.56s/it, grad_norm=3.05, loss=0.838, lr=1.62e-5]Training steps:  49%|████▉     | 98/200 [09:13<09:19,  5.49s/it, grad_norm=3.05, loss=0.838, lr=1.62e-5]Training steps:  49%|████▉     | 98/200 [09:13<09:19,  5.49s/it, grad_norm=1.02, loss=0.205, lr=1.62e-5]02/03/2025 15:49:08 - INFO - trainer - Memory after epoch 49: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  50%|████▉     | 99/200 [09:18<09:20,  5.55s/it, grad_norm=1.03, loss=0.206, lr=1.62e-5]Training steps:  50%|████▉     | 99/200 [09:18<09:20,  5.55s/it, grad_norm=1.05, loss=0.228, lr=1.61e-5]Training steps:  50%|█████     | 100/200 [09:24<09:08,  5.49s/it, grad_norm=1.05, loss=0.228, lr=1.61e-5]Training steps:  50%|█████     | 100/200 [09:24<09:08,  5.49s/it, grad_norm=0.889, loss=0.211, lr=1.61e-5]02/03/2025 15:49:18 - INFO - trainer - Memory after epoch 50: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  50%|████▉     | 99/200 [09:19<09:21,  5.55s/it, grad_norm=1.02, loss=0.205, lr=1.62e-5]Training steps:  50%|████▉     | 99/200 [09:19<09:21,  5.55s/it, grad_norm=1.05, loss=0.228, lr=1.61e-5]Training steps:  50%|█████     | 100/200 [09:24<09:08,  5.48s/it, grad_norm=1.05, loss=0.228, lr=1.61e-5]Training steps:  50%|█████     | 100/200 [09:24<09:08,  5.48s/it, grad_norm=0.887, loss=0.211, lr=1.61e-5]02/03/2025 15:49:19 - INFO - trainer - Memory after epoch 50: {
    "memory_allocated": 26.436,
    "memory_reserved": 54.115,
    "max_memory_allocated": 36.818,
    "max_memory_reserved": 54.115
}
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
80
Training steps:  50%|█████     | 101/200 [09:29<09:08,  5.54s/it, grad_norm=0.889, loss=0.211, lr=1.61e-5]Training steps:  50%|█████     | 101/200 [09:29<09:08,  5.54s/it, grad_norm=0.54, loss=0.202, lr=1.61e-5] slurmstepd: error: *** STEP 131295.0 ON nid005108 CANCELLED AT 2025-02-03T15:49:27 ***
/usr/local/lib/python3.10/dist-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.
  warnings.warn(
usage: Accelerate launch command [-h] [--config_file CONFIG_FILE] [--quiet]
                                 [--cpu] [--multi_gpu] [--tpu] [--ipex]
                                 [--mixed_precision {no,fp16,bf16,fp8}]
                                 [--num_processes NUM_PROCESSES]
                                 [--num_machines NUM_MACHINES]
                                 [--num_cpu_threads_per_process NUM_CPU_THREADS_PER_PROCESS]
                                 [--enable_cpu_affinity]
                                 [--dynamo_backend {no,eager,aot_eager,inductor,aot_ts_nvfuser,nvprims_nvfuser,cudagraphs,ofi,fx2trt,onnxrt,tensorrt,aot_torchxla_trace_once,torhchxla_trace_once,ipex,tvm}]
                                 [--dynamo_mode {default,reduce-overhead,max-autotune}]
                                 [--dynamo_use_fullgraph]
                                 [--dynamo_use_dynamic] [--use_deepspeed]
                                 [--use_fsdp] [--use_megatron_lm] [--use_xpu]
                                 [--gpu_ids GPU_IDS] [--same_network]
                                 [--machine_rank MACHINE_RANK]
                                 [--main_process_ip MAIN_PROCESS_IP]
                                 [--main_process_port MAIN_PROCESS_PORT]
                                 [-t TEE] [--log_dir LOG_DIR] [--role ROLE]
                                 [--rdzv_backend RDZV_BACKEND]
                                 [--rdzv_conf RDZV_CONF]
                                 [--max_restarts MAX_RESTARTS]
                                 [--monitor_interval MONITOR_INTERVAL] [-m]
                                 [--no_python] [--tpu_cluster]
                                 [--no_tpu_cluster] [--tpu_use_sudo] [--vm VM]
                                 [--env ENV]
                                 [--main_training_function MAIN_TRAINING_FUNCTION]
                                 [--downcast_bf16]
                                 [--deepspeed_config_file DEEPSPEED_CONFIG_FILE]
                                 [--zero_stage ZERO_STAGE]
                                 [--offload_optimizer_device OFFLOAD_OPTIMIZER_DEVICE]
                                 [--offload_param_device OFFLOAD_PARAM_DEVICE]
                                 [--offload_optimizer_nvme_path OFFLOAD_OPTIMIZER_NVME_PATH]
                                 [--offload_param_nvme_path OFFLOAD_PARAM_NVME_PATH]
                                 [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]
                                 [--gradient_clipping GRADIENT_CLIPPING]
                                 [--zero3_init_flag ZERO3_INIT_FLAG]
                                 [--zero3_save_16bit_model ZERO3_SAVE_16BIT_MODEL]
                                 [--deepspeed_hostfile DEEPSPEED_HOSTFILE]
                                 [--deepspeed_exclusion_filter DEEPSPEED_EXCLUSION_FILTER]
                                 [--deepspeed_inclusion_filter DEEPSPEED_INCLUSION_FILTER]
                                 [--deepspeed_multinode_launcher DEEPSPEED_MULTINODE_LAUNCHER]
                                 [--deepspeed_moe_layer_cls_names DEEPSPEED_MOE_LAYER_CLS_NAMES]
                                 [--fsdp_offload_params FSDP_OFFLOAD_PARAMS]
                                 [--fsdp_min_num_params FSDP_MIN_NUM_PARAMS]
                                 [--fsdp_sharding_strategy FSDP_SHARDING_STRATEGY]
                                 [--fsdp_auto_wrap_policy FSDP_AUTO_WRAP_POLICY]
                                 [--fsdp_transformer_layer_cls_to_wrap FSDP_TRANSFORMER_LAYER_CLS_TO_WRAP]
                                 [--fsdp_backward_prefetch FSDP_BACKWARD_PREFETCH]
                                 [--fsdp_state_dict_type FSDP_STATE_DICT_TYPE]
                                 [--fsdp_forward_prefetch FSDP_FORWARD_PREFETCH]
                                 [--fsdp_use_orig_params FSDP_USE_ORIG_PARAMS]
                                 [--fsdp_cpu_ram_efficient_loading FSDP_CPU_RAM_EFFICIENT_LOADING]
                                 [--fsdp_sync_module_states FSDP_SYNC_MODULE_STATES]
                                 [--fsdp_activation_checkpointing FSDP_ACTIVATION_CHECKPOINTING]
                                 [--megatron_lm_tp_degree MEGATRON_LM_TP_DEGREE]
                                 [--megatron_lm_pp_degree MEGATRON_LM_PP_DEGREE]
                                 [--megatron_lm_num_micro_batches MEGATRON_LM_NUM_MICRO_BATCHES]
                                 [--megatron_lm_sequence_parallelism MEGATRON_LM_SEQUENCE_PARALLELISM]
                                 [--megatron_lm_recompute_activations MEGATRON_LM_RECOMPUTE_ACTIVATIONS]
                                 [--megatron_lm_use_distributed_optimizer MEGATRON_LM_USE_DISTRIBUTED_OPTIMIZER]
                                 [--megatron_lm_gradient_clipping MEGATRON_LM_GRADIENT_CLIPPING]
                                 [--fp8_backend {te,msamp}]
                                 [--fp8_use_autocast_during_eval]
                                 [--fp8_margin FP8_MARGIN]
                                 [--fp8_interval FP8_INTERVAL]
                                 [--fp8_format {E4M3,HYBRID}]
                                 [--fp8_amax_history_len FP8_AMAX_HISTORY_LEN]
                                 [--fp8_amax_compute_algo {max,most_recent}]
                                 [--fp8_override_linear_precision FP8_OVERRIDE_LINEAR_PRECISION]
                                 [--fp8_opt_level {O1,O2}]
                                 [--aws_access_key_id AWS_ACCESS_KEY_ID]
                                 [--aws_secret_access_key AWS_SECRET_ACCESS_KEY]
                                 [--debug] [--mpirun_hostfile MPIRUN_HOSTFILE]
                                 [--mpirun_ccl MPIRUN_CCL]
                                 training_script ...
Accelerate launch command: error: unrecognized arguments: --distributed_type
srun: error: nid007417: task 0: Exited with exit code 2
srun: Terminating StepId=131340.0
srun: error: nid007418: task 1: Terminated
srun: Force Terminated StepId=131340.0
